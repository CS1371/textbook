<!DOCTYPE HTML>
<html>
<head>
<title>17_Graphs</title>
<!-- include bootstrap -->
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"></script>
<!-- include stylesheets -->
<link rel="stylesheet" href="styles/styles.css" />
<script async src="./javascript/index.js"></script>
</head>
<body>

<div class="nav-obj">#nav_obj#</div>

<div class="content">
  <h1 align="center">Chapter 17: Graphs</h1>

  <!-- Chapter Objectives -->
  <h1>Chapter Objectives</h1>
  <div class="container">
      <p>This chapter demonstrates two algorithms that solve two problems that frequently occur in engineering:</p>
      <ul>
          <li>finding the minimum spanning tree for a graph and</li>
          <li>finding the best path through a graph.</li>
      </ul>
      <p>However, before we can approach these algorithms, we need to understand the following:</p>
      <ul>
          <li>How to construct and use three special forms of data collection: stacks, queues and priority queues<li>How to build a model of a graph, and</li>
          <li>How to traverse and search a graph.</li>
      </ul>
  </div>

  <!-- Introduction -->
  <h1>Introduction</h1>
  <div class="container clearfix">
      <div class="float-sm-right card">
        <img src="Fig_17_1.jpg" alt="Figure 17.1" class="fig card-image">
        <p class="figure-name card-title">Figure 17.1: Street Map of Atlanta</p>
      </div>
      <p>We first consider the nature of a graph by considering Figure 17.1, a simplified street map of the city of Atlanta taken with permission from the OpenStreetMap project. The data storage tools we have considered so far - vectors, arrays, structure arrays, and cell arrays - have essentially been collections whose elements are linearly related to each other by being organized in rows and columns. However, practical engineering frequently meets data that are not organized so easily. Graphs are one such data set. The ultimate goal of this chapter is to discuss this most general form of data structure. We need first to resolve the semantic problem of the name "graph." We typically think of a graph as a plot. However, in computer science, a graph is a collection of nodes connected by edges. A street map might be a useful mental model of a graph where the streets are the edges and the intersections are the nodes. To process graphs effectively, we must first consider three simpler concepts: stacks, queues in general and priority queues in particular.</p>
  </div>

  <div class="chp-section" data-sect-num="1" data-sect-name="Stacks">
    <!-- Stacks -->
    <h2 id="17_1">17.1  Stacks</h2>
    <div class="container">
        <p>We briefly discussed the concept of stacks in Chapter 9 where a specific kind of stack, the Activation Stack, is used to manage the workspace of each function currently active in Matlab. We first consider the general nature and implementation of stacks as special collections that enable us to process graphs efficiently. We experience the concept of a stack every day of our lives. We reproduce here the illustration from Chapter 9 of the plates in the cafeteria.</p>
    </div>

    <div class="chp-subsection" data-sub-num="1" data-sub-name="The Nature of a Stack">
      <!-- The Nature of a Stack -->
      <h3 id="17_1_1">17.1.1	The Nature of a Stack</h3>
      <div class="container clearfix">
          <div class="float-sm-right card">
            <img src="Fig_9_1.jpg" alt="Figure 17.2" class="fig card-image">
            <p class="figure-name card-title">Figure 17.2: A Typical Stack</p>
          </div>
          <p>Formally, we refer to a stack as a Last In/First Out (LIFO) collection, as illustrated in Figure 17.2. The most general form of a stack is permitted to contain any kind of object, that is, an instance of any data type or class. The plates in the illustration are surrogates for literally anything that could be stored in a Matlab variable. A cell array, therefore, would be a good underlying structure upon which to build stack behavior. Typically, operations on a stack are restricted to the following:</p>
          <ul>
              <li><b>push</b>: puts an object onto the top of the stack,</li>
              <li><b>dequeue</b>: removes an object from the top of the stack</li>
              <li><b>peek</b>: copies the first object from the stacck without removing it, and</li>
              <li><b>isempty</b> determines whether the stack is empty.</li>
          </ul>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="2" data-sub-name="Implementing Stacks">
      <!-- Implementing Stacks -->
      <h3 id="17_1_2">17.1.2	Implementing Stacks</h3>
      <div class="container">
          <p>Although there are many ways to implement a stack, a cell array is a good choice because it is a linear collection of objects that may be of any type and can be extended or shortened without any apparent effort. If we establish a stack using a cell array, the implementation of the above behavior is almost trivial. One rather strange characteristic is the need to return the modified stack to the user. The Matlab tools are:</p>
          <ul>
              <li><code>stk = push(stk, item)</code> concatenates data at the end of the cell array returning the new stack to the user</li>
              <li><code>[stk, item] = pop(stk)</code>: removes the item from the end of the cell array and returns that item and the modified stack to the user</li>
              <li><code>item = peek(stk)</code>: merely returns the end item in the cell array not returning the stack because it doesn't changed</li>
              <li><code>res = isempty(stk)</code>: is the standard MATLAB test for the empty vector.</li>
          </ul>
          <p>Clearly, because all the cell array operations are also accessible to the programmer, nothing prevents an unscrupulous programmer from using other operations on the stack — for example, adding an item elsewhere that the top of the stack. There are computer tools in Object-Oriented Programming that completely encapsulate the data and only permit the specified functions, but the author recommends that a computer language other than Matlab would be more appropriate if you must have this kind of security in your data.</p>
      </div>
    </div>
  </div>

  <div class="chp-section" data-sect-num="2" data-sect-name="Queues">
    <!-- Queues -->
    <h2 id="17_2">17.2  Queues</h2>
    <div class="container">
        <p>We first consider the nature and implementation of queue that, like a stack, provides special collections that enable us to process graphs efficiently. We experience the concept of a queue every day of our lives. A line of cars waiting for the light to turn green is a queue; when we stand in line at a store or send a print job to a printer, we experience typical queue behavior. In general, the first object entering a queue is the first one to exit the other end.</p>
    </div>

    <div class="chp-subsection" data-sub-num="1" data-sub-name="The Nature of a Queue">
      <!-- The Nature of a Queue -->
      <h3 id="17_2_1">17.2.1	The Nature of a Queue</h3>
      <div class="container clearfix">
          <div class="float-sm-right card">
            <img src="Fig_17_3.jpg" alt="Figure 17.3" class="fig card-image">
            <p class="figure-name card-title">Figure 17.3: A Typical Queue - Rabbits at Starbucks</p>
          </div>
          <p>Formally, we refer to a queue as a first in/first out (FIFO) collection, as illustrated in Figure 17.3. As with stacks, the most general form of a queue is permitted to contain any kind of object. Typically, operations on a queue are restricted to the following:</p>
          <ul>
              <li><b>enqueue</b> puts an object onto the queue</li>
              <li><b>dequeue</b> removes an object from the queue</li>
              <li><b>peek</b> copies the first object out of the queue without removing it, and</li>
              <li><b>isempty</b> determine whether the queue is empty.</li>
          </ul>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="2" data-sub-name="Implementing Queues">
      <!-- Implementing Queues -->
      <h3 id="17_2_2">17.2.2	Implementing Queues</h3>
      <div class="container">
          <p>As with stacks, a cell array is a good choice upon which to build a queue because it is a linear collection of objects that may be of any type and can be extended or shortened without any apparent effort. If we establish a queue using a cell array, the implementation of the above behavior is trivial:</p>
          </ul>
              <li><code>q = enqueue(q, item)</code> concatenates data at the end of the cell array</li>
              <li><code>[q item] = dequeue(q)</code> removes the item from the front of the cell array and returns that item to the user</li>
              <li><code> item = peek(q)</code> merely accesses the first item in the cell array</li>
              <li><code> res = isempty(q)</code> is the standard MATLAB test for the empty vector</li>
          </ul>
          <p>As with stacks, in a real application, you might want to implement your queue with a tool set that protects the integrity of the data, and as with stacks, Matlab is physically incapable of providing this service.</p>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="3" data-sub-name="Priority Queues">
      <!-- Priority Queues -->
      <h3 id="17_2_3">17.2.3 Priority Queues</h3>
      <div class="container clearfix">
          <div class="float-sm-right card">
            <img src="Fig_17_4.jpg" alt="Figure 17.4" class="fig card-image">
            <p class="figure-name card-title">Figure 17.4: A Priority Queue</p>
          </div>
          <p>There are times when we wish ordinary queues were priority queues. For example, at the printer where you wait an hour for one page while someone prints large sections of an encyclopedia and you wonder why the print queue can’t put really small jobs ahead of really large jobs.  The only difference between an ordinary queue and a priority queue is that the objects on the queue emerge in a specified order. The rabbits in Figure 14.4 are sorted  by the expected time to prepare the drink they want. This sorting may be accomplished either as the items are enqueued as illustrated below, or by searching for the "best" item when performing a dequeue operation.  The efficiency will be the same.</p>
          <p>In our mechanization of a priority queue, the enqueue function involves adding the new item in order to the queue. For this to happen, there must be a means of comparing two objects. Here, we use the function <code>is_before</code> that generally should be able to compare any two objects.  In this implementation, it is sufficient to be able to compare numbers, strings or structures that contain either the <code>fields</code> key or NaN. Clearly, this function can be extended as necessary to compare any two objects.</p>
      </div>
    </div>
  </div>

  <div class="chp-section" data-sect-num="3" data-sect-name="Testing Stacks and Queues">
    <!-- Testing Stacks and Queues -->
    <h3 id="17_3">17.3 Testing Stacks and Queues</h3>
    <div class="container">
        <p>It is always advisable to test utility functions thoroughly before using them in complex algorithms. Listing 17.1 shows a script that tests a stack, a queue and a priority queue.  Following that script as helper functions are the simple functions that implement all the necessary tools.</p>
        <div class="listing">#listing_17_1#</div>
    </div>
  </div>

  <div class="chp-section" data-sect-num="4" data-sect-name="Graphs">
    <!-- Graphs -->
    <h2 id="17_4">17.4 Graphs</h2>
    <div class="container">
        <p> This chapter focuses on processing a graph — the most general form of dynamic data structure, an arbitrary collection of nodes connected by edges. The edges may be directional to indicate that the graph can be traversed along that edge in only one direction (like a one-way street). The edges may also have a value associated with them to indicate, for example, the cost of traversing that edge. We refer to this as a weighted graph. For a street map, this cost could either be the distance, or in a more sophisticated system, the travel time—a function of the distance, the speed limit, and the traffic congestion. Graphs are not required to be completely connected, and they may contain cycles - closed loops in which the unwary algorithm could become trapped. Graphs also have no obvious starting and stopping points. Finally, a path on a graph is a connected list of edges that is the result of traversing a graph.</p>
    </div>

    <div class="chp-subsection" data-sub-num="1" data-sub-name="Graph Examples">
      <!-- Graph Examples -->
      <h3 id="17_4_1">17.4.1 Graph Examples</h3>
      <div class="container clearfix">
          <div class="float-sm-right card">
              <img src="Fig_17_5.jpg" alt="Figure 17.5" class="fig card-image">
              <p class="figure-name card-title">Figure 17.5: A Simple Graph</p>
          </div>
          <p>A simple graph is shown in Figure 17.5. In the figure, the connection points 0 ... 10 are the nodes and the edges are the interconnecting lines, which in this example are not directional but are weighted. Graphs occur frequently in everyday life, as illustrated by the street map shown in Figure 17.1. Street maps can be conveniently represented as graphs where intersections are the nodes and streets are the edges. Streets can be directional (one-way), and they may have weights associated with them - either the transit time (a function of the length of the street and its speed limit) or, with access to real-time traffic information, a more complex estimate of the transit time.</p>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="2" data-sub-name="Processing Graphs">
      <!-- Processing Graphs -->
      <h3 id="17_4_2">17.4.2	Processing Graphs</h3>
      <div class="container">
        <p>In designing algorithms that operate on graphs in general, we need to consider the following constraints:</p>
        <ul>
            <li>With cycles permitted in the data, there is no natural starting point like the beginning of a cell array. Consequently, the user must always specify a place on the graph to start as well as the place to stop.</li>
            <li>There are no natural “leaf nodes” where a search might have to stop and back up. Consequently, an algorithm processing a graph must have a means of determining that being at a given node is the “end of the line.” Typically, this is accomplished by maintaining a collection of visited nodes as it progresses around the graph. Each time a node is considered, the algorithm must check to see whether that node is already in the visited collection. If so, it refuses to return to that node. The algorithm must backtrack if it reaches a node from which there is no edge to a node that has not already been visited.</li>
            <li>Whereas on a cell array there is only one feasible path from one node to another, there may be many possible paths between two nodes on a graph. The best algorithms that search for paths must take into account a comparison between paths to determine the best one.  For a simple, consistent example, consider the graph shown in Figure 17.5. We will use this simple example to demonstrate minimum spanning trees (MSTs) and finding paths through the graph.</li>
        </ul>
      </div>
    </div>
  </div>

  <div class="chp-section" data-sect-num="5" data-sect-name="Minimum Spanning Trees">
    <!-- Minimum Spanning Trees -->
    <h2 id="17_5">17.5 Minimum Spanning Trees</h2>
    <div class="container clearfix">
        <p>A Spanning Tree (MST) is a set of edges identified for a graph that touches all of the nodes of the graph. For example, on a circuit board, power must be distributed to all of the chips on the board. The routing of a power trace to all the power pins would be a spanning tree. More often that not, it is important to have a spanning tree whose length is as short as possible. Finding the shortest spanning tree is referred to as the Minimum Spanning Tree (MST) problem. There may well be multiple spanning trees with the same overall cost and any one of those would satisfy the requirement. There are two practical algorithms commonly used to solve the MST problem:</p>
        <ul>
            <li> Kruscal’s algorithm
            <li> Prim's algorithm
        </ul>
        <div class="float-sm-right card">
          <video controls class="card-image"><source src="MST.mp4" type="video/mp4">Fig 17.6 Animation of Prim's MST Algorithm</video>
          <p class="figure-name card-title">Fig 17.6: Animation of Prim's MST Algorithm</p>
        </div>
        <p>Since they are both very similar in concept and produce the correct answer, we will only consider one: Prim's algorithm.</p>
        <p>Prim’s algorithm finds the subset of the edges of the graph that connect every node exactly once whose total cost is not greater than that of any other spanning tree. The algorithm continuously increases the size of a tree, one edge at a time, starting with a tree consisting of a single node, until it spans all the nodes. Specifically, given a graph as defined in Figure 17.5, Prim’s algorithm proceeds as shown in Listing 17.2.</p>
        <p>Figure 17.6 is a pair of animations of Prim's algorithm applied to a small graph and then a larger, but still manageable graph.</p>
    </div>
    <div class="listing">#listing_17_2#</div>
</div>

  <div class="chp-section" data-sect-num="6" data-sect-name="Finding Paths through a Graph">
    <!-- Finding Paths through a Graph -->
    <h2 id="17_6">17.6 Finding Paths through a Graph</h2>
    <div class="container">
        <p>This section discusses four algorithms for finding a path from one node on the graph to another. The first three algorithms exhaustively search the graph to find the absolute best path between node pairs by different criteria. These differences of behavior are created by selecting a stack, a queue or a priority queue as the dynamic container for interim solutions.  The fourth is one of many approximation algorithms typically used to compute a good enough route in circumstances where an exact solution is not feasible.</p>
        <p>Listing 17.3 shows a template for the three exact algorithms.</p>
        <div class="listing">#listing_17_3#</div>
        <p>In this listing, we will use a generic <code>&lt;collection&gt;</code> to substitute for the specific collections used in the detailed algorithms to follow. We will also use the generic operations <code>&lt;add(...)&gt;</code> and <code>&lt;remove(...)&gt;</code> as surrogates for the actual operations on the chosen <code>&lt;collection&gt;</code>. Our objective will be to return a <code>&lt;path&gt;</code> consisting of a sequence of 1 or more nodes.  We will also need the concept of <code>&lt;children&gt;</code> which is a collection of edges [u,v] where u is the end of the path and v is not on the current path to prevent cycles in the path. When choosing which child node to process first, we need a consistent rule. Since our nodes are all numbered, it makes sense to process the child nodes in increasing numerical order. This will be the rule for all the specific examples to follow.</p>
        <p>For the following three algorithms, we will see two artifacts:</p>
        <ul>
            <li> animations on two graphs showing how the algorithm works.  The algorithms on first, small graph will always start at node 1 and stop at node 7. On the larger graph, they start at node 121 and stop at node 1. Comparing these animations will illustrate the relative computational cost of each algorithm. However, as we will see in section 17.6.4, none of these algorithms are fast enough to handle a graph of any serious size.</li>
            <li> the contents of the collection at the end of each of the algorithms in the simple case.</li>
        </ul>
        <p>A serious student will want to trace through the template in Listing 17.3 referring to the animations in order to construct the contents of each collection.</p>
    </div>

    <div class="chp-subsection" data-sub-num="1" data-sub-name="Depth-First Search">
      <!-- Depth-First Search -->
      <h3 id="17_6_1">17.6.1	Depth-First Search (DFS)</h3>
      <div class="container">
          <p>The depth-first path search algorithm uses a stack for the <code>&lt;collection&gt;</code> and <code>&lt;push(...)&gt;</code> and <code>&lt;pop(...)&gt;</code> as the functions to add and remove a path from the stack. As we observe the behavior of the DFS algorithm, it is clearly the fastest of the three algorithms, but makes no claim at all about the efficiency of the resulting path. As long as there is any connectivity between the starting and ending nodes, this will find a path.</p>
          <p>As you study the small graph, you would be right to "ask why bother with the stack at all?" since at every cycle through the template, the algorithm always takes the last element pushed onto the stack. As you will see on a careful study of the DFS algorithm on the larger graph, the stack is there to resolve the problem of cul-de-sacs. As in real streets that have no outlet, a cul-de-sac can be a physical constraint. However, there can also be logical cul-de-sacs where a street closes a loop and has no other outlet. The rule to eliminate cycles will also see this geometry as a virtual cul-de-sac.  In either case, the paths on the stack can be popped off until the algorithm reaches a node with an alternative path to proceed. The logic of template in Listing 17.3 will exit from the while loop if there are no more feasible paths on the stack.</p>
          <div class="row">
              <div class="col-sm-7 card">
                  <video controls class="card-image"><source src="DFS.mp4" type="video/mp4">Fig 17.7 Animation of DFS Algorithm</video>
                  <p class="figure-name card-title">Fig 17.7: Animation of the DFS Algorithm</p>
              </div>
              <div class="col-sm-5 card">
                  <div class="fig-long">
                      <img src="DFS.jpg" alt="Figure 17.8" class="fig card-image">
                  </div>
                  <p class="figure-name card-title">Figure 17.8: Stack after the first DFS search</p>
              </div>
          </div>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="2" data-sub-name="Breadth-First Search">
      <!-- Breadth-First Search -->
      <h3 id="17_6_2">17.6.2	Breadth-First Search (BFS)</h3>
      <div class="container clearfix">
          <p>Frequently, we actually need the path with the smallest number of nodes between the starting and ending nodes. For example, because changing trains involves walking and waiting, the best path on an urban transit system map is that with the fewest changes, even if the resulting path is longer. To search for the path with the least nodes, we need an algorithm that performs a Breadth-First Search (BFS) on a graph. We will use the template in Listing 17.3 where the <code>&lt;collection&gt;</code> is a <code>&lt;queue&gt;</code>, the <code>&lt;add&gt;</code> method is <code>&lt;enqueue(...)&gt;</code> and the &lt;remove(...)&gt; method is <code>&lt;dequeue(...)&gt;</code>.</p>
          <p>As you observe the animations in Figure 17.9, especially the larger graph, you will see a characteristic rotating search mimicking the ripples on a pond when a pebble is dropped in. This behavior is caused by using the <code>&lt;queue(...)&gt;</code> and will result in the path with the least number of nodes although it may not be the shortest one.  In fact, on the small graph animation, while there is a path with lower cost that uses one more node, the BFS algorithm can't find it. Figure 17.9 shows animations of the same two problems using the BFS algorithm - a better approach in that it computes the path with the least number of nodes, but does not guarantee the best cost.  In fact, neither DFS nor BFS take cost into account, but merely use it as an observer.  Figure 17.10 shows to state of the queue at the end of the first animation.</p>
          <div class="row">
              <div class="col-sm-7 card">
                  <video controls class="card-image"><source src="BFS.mp4" type="video/mp4">Fig 17.9: Animation of the BFS Algorithm</video>
                  <p class="figure-name card-title">Fig 17.9: Animation of the BFS Algorithm</p>
              </div>
              <div class="col-sm-5 card">
                  <div class="fig-long">
                      <img src="BFS.jpg" alt="Figure 17.10" class="fig card-image">
                  </div>
                  <p class="figure-name card-title">Fig 17.10: Queue after the first BFS search</p>
              </div>
          </div>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="3" data-sub-name="Dijkstra's Algorithm">
      <!-- Dijkstra's Algorithm -->
      <h3 id="17_6_3">17.6.3	Dijkstra’s Algorithm</h3>
      <div class="container">
          <p>Although the minimal number of nodes is sometimes the right answer, frequently there is a path that uses more nodes but has a smaller overall cost. This is evident from a quick glance at Figure 17.5: the path 1-0-5-6-7 has a lower cost than the path 1-0-4-7 found by the BFS algorithm, which actually ignores the edge weights. Many algorithms exist for finding the optimal path through a graph. Here we illustrate the algorithm attributed to the Dutch computer scientist Dr. Edsger Dijkstra. Perhaps it is not the most efficient algorithm; but for our purposes, this approach has the virtue of being a minor extension to the while loop algorithm described in Listing 17.3.  The major differences arise from the use of a priority queue in place of the normal queue used in the BFS algorithm.</p>
          <ul>
              <li> As previously noted, priority queues differ from basic queues only to the extent that the <code>&lt;enqueue(...)&gt;</code> method puts the data in order, rather than at the tail of the queue. The ordering criterion required by the algorithm is to place the paths in increasing order of path cost. While we have not explicitly dealt with the Big O of these algorithms, it is clear in the micro sense that inserting at the end of a queue is O(1) while inserting in order in a priority queue is O(N) where N is the worst case of queue length.</li>
              <li>The objects contained in the priority queue need to contain not only the path, but also the total path weight.</li>
              <li> we have to change the exit strategy in the template shown in Listing 17.2.  For DFS and BFS, once a path has been added to their collections, there is no possibility of a "better" path being inserted ahead of that result. Hence, it is fine to perform the exit test when inserting each child node.  However, this is not the case for the Dijkstra algorithm; better paths can be inserted before any of the paths entered. In a formal sense, it is safe to perform the exit test when a path is dequeued. However, when preparing the somewhat intimidating view of the priority view when the algorithm completed, we shortened that queue by realizing that the algorithm may be stopped when a path of cost N to the end is enqueued if it is logically impossible for the next step on any of the surviving shorter paths to reach the ending node with a cost less than N.</li>
          </ul>
          <p>Figures 17.11 and 17.12 show the animations for the same two problems and the resulting priority queue for the smaller case. While this algorithm does compute the path with the lowest cost, it does so at considerable extra computation cost, as is evident from the run time of the second animation, the increased Big O if the enqueue method and the enormous amount of extra stuff packed into the priority queue in Figure 17.12.</p>
          <div class="row">
              <div class="col-sm-7 card">
                  <video controls class="card-image"><source src="Optimal.mp4" type="video/mp4">Fig 17.11: Animation of Dijkstra's Algorithm</video>
                  <p class="figure-name card-title">Fig 17.11: Animation of Dijkstra's Algorithm</p>
              </div>
              <div class="col-sm-5 card">
                  <div class="fig-long">
                      <img src="Opt_p_q.jpg" alt="Figure 17.12" class="fig card-image">
                  </div>
                  <p class="figure-name card-title">Fig 17.12: Priority Queue after the first search</p>
              </div>
          </div>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="4" data-sub-name="An Approximation Algorithm">
      <!-- An Approximation Algorithm -->
      <h3 id="17_6_4">17.6.4	An Approximation Algorithm</h3>
      <div class="container clearfix">
          <p>As we progressed from DFS to BFS to Dijkstra's algorithm, the answers became more precise, but the computational cost was increasing.  Even for a really small proportion of the streets in the Atlanta metropolitan area, the solution became unpleasantly slow. Yet, the Satellite Navigation system on any car  can compute the route from somewhere in the Atlanta, Georgia area to the suburbs of Los Angeles, California in a second or less. To understand how this can work, we need to look at a fundamental change in the path computation algorithm and then, in Section 17.6.5 examine some additions to that algorithm to improve the efficiency and remove some occasional strange behavior.</p>
          <div class="float-sm-right">
              <div class="card">
                  <video controls class="card-image"><source src="Greedy.mp4" type="video/mp4">Fig 17.13: Animation of a Greedy Algorithm</video>
                  <p class="figure-name card-title">Fig 17.13: Animation of a Greedy Algorithm</p>
              </div>
              <div class="card">
                  <img src="greedy.jpg" alt="Figure 17.14" class="fig card-image">
                  <p class="figure-name card-title">Figure 17.14: Greedy Algorithm at Work</p>
              </div>
          </div>
          <p>First, we change the fundamental algorithm - we will give up the desire for an exact solution and settle for a strategy that gives us a good enough answer most of the time.  There are many such algorithms that are collectively referred to as "Greedy" algorithms. A greedy algorithm will produce a solution as long as the graph has sufficient continuity, but is not guaranteed to produce the best. In addition to the cost of each edge, it also requires that each node be aware of its geographic location. Figure 17.13 shows the usual animations using a crude greedy algorithm.  Don't blink - you might miss it all.</p>
          <p>The algorithm is quite simple:</p>
          <ol>
              <li>Beginning at the starting node, it evaluates the result of traveling along each of the feasible edges to a child node eliminating cyclic paths. The evaluation takes the form of summing the cost of that edge and an estimate of the cost from that node to the destination. On a street map, for example, the estimated cost of each step would be the length of the edge and the straight-line distance from the new node to the destination.</li>
              <li>It selects the step with the least cost, adds the node reached to the path, and repeats step 1 until the destination is reached, only back-tracking when it hits a physical or logical cul-de-sac.</li>
              <li>Back-tracking is sometimes necessary if a node is reached from which there are no feasible paths, such as driving into a physical or logical cul-de-sac.</li>
              <li>Complete failure is possible, as it is for the other algorithms, if no physical path exists between the origin and destination nodes.</li>
              <li> it is also possible to produce a really silly answer. For example, consider the local street situation shown in Figure 17.14. This is a caricature of my first experiment on the first car I bought that had GPS. Suppose I were to ask for a route from my home to some destination to the South. The path would start with A - D, and it would try and reject B and C when they reached their respective cul-de-sacs. To choose between the remaining children E and J, it would choose E because with any destination to the South, D - E plus E to the destination is shorter. But what about a destination to the North? D - J is then better than D - E, so on my first test of my new Nav system, the stupid thing wants me to go around the loop D - J - K - L - F ...!</li>
          </ol>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="5" data-sub-name="Serious Path Finding Algorithms">
      <!-- Serious Path Finding Algorithms -->
      <h3 id="17_6_5">17.6.5	Serious Path Finding Algorithms</h3>
      <div class="container">
          <p>We have seen earlier that theoretical algorithms are OK for small problems, but for commercial algorithms that process large quantities of data, much care must be taken to ensure that the algorithm is fast enough and covers the nasty cases that make algorithms look foolish.</p>
          <ul>
              <li><b>"Layering" the problem</b>: Returning to the Sat Nav problem of finding a path from a house in Atlanta to a house in Los Angeles, if you were personally planning that route, you would not need to consider all the surface streets across the country. Rather, you would probably use a greedy algorithm to compute the route from the starting place to the nearest expressway on ramp, and from the destination to the nearest off ramp. The remains of the trip would be taken care of with a greedy algorithm on expressways only from the selected on ramp to the selected off ramp, and then stitch the three paths together.</li>
              <li><b>Informed Search</b>: A number of researchers have enhanced the basic greedy algorithm to avoid the silly solutions.  A* is one such algorithm. It uses heuristics to maintain a small number of competing paths until they either became to costly or merged to a point where the best can be selected. One aspect of the algorithm design is choosing how many paths to maintain. This becomes a trade-off between computational speed and the need to avoid ridiculous behavior.  A normal greedy algorithm is the fast end of that spectrum and algorithms like Dijkstra's is the slow end.</li>
          </ul>
      </div>
    </div>
  </div>

  <div class="chp-section" data-sect-num="7" data-sect-name="Engineering Applications">
    <!-- Engineering Applications -->
    <h2 id="17_7">17.7	Engineering Applications</h2>
    <div class="container">
        <p>Many practical engineering problems can be characterized as graph search problems.</p>
    </div>

    <div class="chp-subsection" data-sub-num="1" data-sub-name="Simple Applications">
       <!-- Simple Applications -->
      <h3 id="17_7_1">17.7.1	Simple Applications</h3>
      <div class="container">
          <p>MSTs are used by utility companies to find the least amount of cable that must be used to wire a subdivision.  Approximate path finding is used, for example, in navigation systems that use GPS to find the current position of the vehicle and an approximate, greedy algorithm to determine the route to a destination.  Exact path finding is used to optimize the flight profile of commercial aircraft outside FAA-managed air space and can save as much as 10% of the fuel burned on every flight.</p>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="2" data-sub-name="Complex Extensions">
      <!-- Complex Extensions -->
      <h3 id="17_7_2">17.7.2	Complex Extensions</h3>
      <div class="container">
          <p>In addition to the obvious examples above, consider these examples:</p>
          <ul>
              <li>designing printed circuit boards is a complex extension of path finding</li>
              <li>stresses in a redundant structure like an aircraft wing seek a path that is in some sense optimal, and</li>
              <li>the 'traveling salesperson problem" is an unpleasant extension of path finding in which the objective is to find the shorted linear path that connects all of the nodes of a graph visiting each exactly once. For example, designing routes for garbage collection or school buses.</li>
          </ul>
          <p>Each of these belongs to a large class of problems called N-P Complete problems, a continued topic of research in many industrial engineering communities.</p>
      </div>
    </div>
  </div>

  <!-- Chapter Summaries -->
  <h2>Chapter Summary</h2>
  <p>This chapter demonstrated effective algorithms for finding good paths through a graph, and included the following:</p>
  <ul>
      <li>How to construct and use queues and priority queues as the underlying mechanism for graph traversal</li>
      <li>Prim’s algorithm for finding the minimum spanning tree of a graph</li>
      <li>Depth-first, Breadth-first and Dijkstra’s algorithms for finding exact paths
      through a graph</li>
      <li>A greedy algorithm for finding approximate paths that are "good enough."</li>
  </ul>

  <!-- Programming Project -->
  <h2>Programming Project</h2>
  <p>Suppose that we would like to validate the assertion that the London Underground is designed to have at most two train changes between any pair of stations.</p>
  <ul>
      <li>Download the underground map from http://content.tfl.gov.uk/standard-tube-map.pdf.</li>
      <li>Then, construct a graph representing the major routes in that system. You will not need all the stations identified for this exercise - only one station per track segment between transfer stations.</li>
      <li>Write some code that will determine the number of train changes to travel between any pair of stations using a breadth-first search to minimize the number of changes.</li>
      <li>Iterate across every pair of stations and find the station pair with the maximum number of train changes.</li>
      <li>Then, for comparison, go to http://metromap.fr/en for the equivalent map of the Paris metro.</li>
  </ul>
</div>


<table align="center">
<tbody>
<tr>
<td><a href="16_Sorting.htm">previous</a></td>
<td><a href="Contents.htm">home</a></td>
<td><a href="Contents.htm">next</a></td>
</tr>
</tbody>
</table>

</body>
</html>
