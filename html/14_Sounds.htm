<!DOCTYPE HTML>
<html>
<head>
<title>14_Sounds</title>
<script async src="./javascript/index.js"></script>
<!-- include bootstrap -->
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"></script>
<!-- main stylesheet -->
<link rel="stylesheet" href="styles/styles.css" />
</head>

<body>
<div>#top_nav#</div>
<div class="nav-obj">#nav_obj#</div>
<div class="content">
  <h1 align="center" id="14">Chapter 14: Sounds</h1>

  <!-- Chapter Objectives -->
  <h1>Chapter Objectives</h1>
  <div class="container">
  <p>This chapter discusses the following:</p>
      <ul>
          <li>How sound<a id="14905"></a> is physically recorded and<a id="14228"></a> played back and<a id="14229"></a> our internal storage of<a id="14699"></a> sound<a id="14906"></a></li>
          <li>Operations that can be performed with<a id="14335"></a> the original time trace</li>
          <li>The ability to<a id="14434"></a> transform the data<a id="14403"></a> into the frequency<a id="14573"></a> domain and<a id="14230"></a> the physical<a id="14158"></a> significance of<a id="14700"></a> the transformed data<a id="14404"></a></li>
          <li>Operations that can be performed in the frequency<a id="14574"></a> domain</li>
      </ul>
  </div>

  <!--
  <h1>Introduction</h1>
   [not needed here] DMS  -->

   <div class="chp-section" data-sect-num="1" data-sect-name="The Physics of Sound">
    <!-- The Physics of Sound -->
    <h2 id="14_1">14.1	The Physics of<a id="14701"></a> Sound</h2>
    <div class="container">
        <p>Any sound<a id="14907"></a> source produces sound<a id="14908"></a> in the form of<a id="14702"></a> pressure fluctuations in the air. While the air molecules move infinitesimal distances in order to<a id="14435"></a> propagate the sound<a id="14909"></a>, the important part of<a id="14703"></a> sound<a id="14910"></a> propagation is that pressure waves move rapidly through the air by causing air molecules to<a id="14436"></a> “jostle” each other. These pressure fluctuations can be viewed as analog signals—data<a id="14405"></a> that have a continuous range of<a id="14704"></a> values. These signals have two attributes: their amplitude and<a id="14231"></a> their frequency<a id="14575"></a> characteristics.</p>
        <p>In absolute terms, sound<a id="14911"></a> is measured as the <b>amplitude</b> of<a id="14705"></a> pressure fluctuations on<a id="14372"></a> a surface<a id="14685"></a> like an eardrum or a microphone. However, the challenging characteristic of<a id="14706"></a> these data<a id="14406"></a> is their dynamic range. Our ears are able to<a id="14437"></a> detect small sounds with<a id="14336"></a> amplitudes around 10<sup>10</sup> (10 billion) times smaller than the loudest comfortable sound<a id="14912"></a>. Sound intensity<a id="15014"></a> is therefore usually reported logarithmically, measured in decibels where the intensity<a id="15015"></a> of<a id="14707"></a> a sound<a id="14913"></a> in decibels is calculated as follows:</p>
        <p><code>I<sub>DB</sub> = 10 log<sub>10</sub>(I / I<sub>0</sub>)</code></p>
        <p>where I is the measured pressure fluctuation and<a id="14232"></a> I<sub>0</sub> is a reference pressure usually established as the lowest pressure fluctuation a really good ear can detect, 2 x 10<sup>−4</sup> dynes/cm<sup>2</sup>.</p>
        <p>Also, sounds are pressure fluctuations at certain <b>frequencies</b>. The human ear can hear sounds as low as 50 Hz and<a id="14233"></a> as high as 20 kHz. Voices on<a id="14373"></a> the telephone sound<a id="14914"></a> odd because the upper frequency<a id="14576"></a> is limited by the telephone equipment to<a id="14438"></a> 4 kHz. Typically, hearing damage due to<a id="14439"></a> aging or exposure to<a id="14440"></a> excessive sound<a id="14915"></a> levels causes an ear to<a id="14441"></a> lose sensitivity to<a id="14442"></a> high and<a id="14234"></a>/or low frequencies.</p>
    </div>
  </div>

  <div class="chp-section" data-sect-num="2" data-sect-name="Recording and Playback">
     <!-- Recording and Playback -->
    <h2 id="14_2">14.2	Recording and<a id="14235"></a> Playback</h2>
    <div class="container clearfix">
        <div class="float-sm-right card">
            <img src="..\Images\Fig_14_1.JPG" alt="Figure 14.1" class="fig card-img">
            <p class="figure-name card-title">Figure<a id="15075"></a> 14.1: Recording and<a id="14236"></a> Playback</p>
        </div>
        <p>Early attempts at sound<a id="14916"></a> recording<a id="14686"></a> concentrated first on<a id="14374"></a> mechanical, and<a id="14237"></a> later magnetic, methods for<a id="15043"></a> storing and<a id="14238"></a> reproducing sound<a id="14917"></a>. The phonograph/record player depended on<a id="14375"></a> the motion of<a id="14708"></a> a needle in a groove as a cylinder or disk rotated at constant speed under the playback<a id="14671"></a> head. Not surprisingly, when you see the incredible dynamic range required, even the best stereos could not reproduce high-quality sound<a id="14918"></a>. Later, analog magnetic tape in various forms replaced the phonograph, offering less<a id="14334"></a> wear on<a id="14376"></a> the recording<a id="14687"></a> and<a id="14239"></a> better, but still limited, dynamic range. Digital recording<a id="14688"></a> has almost completely supplanted analog recording<a id="14689"></a> and<a id="14240"></a> will be the subject of<a id="14709"></a> this chapter.</p>
        <p>Of course, sound<a id="14919"></a> amplitude in analog form is unintelligible to<a id="14443"></a> a computer—it must be turned into an electrical<a id="14147"></a> signal by a microphone, amplified to<a id="14444"></a> suitable voltage levels, digitized, and<a id="14241"></a> stored, as shown in Figure<a id="15076"></a> 14.1. The key to<a id="14445"></a> successful digital recording<a id="14690"></a> and<a id="14242"></a> playback<a id="14672"></a>—whether by digital tape machines, compact disks, or computer files—is the design of<a id="14710"></a> the analog-to<a id="14446"></a>-digital<a id="14127"></a> (A/D) and<a id="14243"></a> digital-to<a id="14447"></a>-analog (D/A) devices. The reader should remember that this is still low-level data<a id="14407"></a>. Each word coming out of<a id="14711"></a> the A/D<a id="14125"></a> or going into the D/A merely represents the pressure on<a id="14377"></a> the microphone at a point in time.</p>
        <p>The primary parameter governing the sound<a id="14920"></a> quality is the recording<a id="14691"></a> rate—how quickly the mechanism records samples of<a id="14712"></a> the sound<a id="14921"></a> (the sampling rate). Basic sampling theory suggests that we should use a sampling rate twice the highest frequency<a id="14577"></a> you are interested in reproducing, usually around 20,000 samples per second for<a id="15044"></a> good music<a id="14148"></a>, 5,000 samples per second for<a id="15045"></a> speech.</p>
        <div class="float-sm-right card technical-insights">
            <p class="card-title">Technical Insight 14.1</p>
            <p class="card-text">The background theory of<a id="14713"></a> sampling is beyond the scope of<a id="14714"></a> this text<a id="15019"></a>. Interested readers should research Nyquist on<a id="14378"></a> a good search engine.</p>
        </div>
        <p>The other parameter, the resolution<a id="14221"></a> of<a id="14715"></a> the recorded data<a id="14408"></a>, has remarkably little effect on<a id="14379"></a> the quality of<a id="14716"></a> the recording<a id="14692"></a> to<a id="14448"></a> an untrained ear. The resolution<a id="14222"></a> is usually either 8 bits (−128 to<a id="14449"></a> 127) or 16 bits (−32,768 to<a id="14450"></a> 32767). While 8-bit resolution<a id="14223"></a> ought to<a id="14451"></a> offer very limited dynamic range, and<a id="14244"></a> theoretically should be used only for<a id="15046"></a> recording<a id="14693"></a> speech, in practice it results in a quality of<a id="14717"></a> reproduction for<a id="15047"></a> music<a id="14149"></a> that is, to<a id="14452"></a> an untrained ear, indistinguishable from<a id="14197"></a>   that   provided   by   16-bit resolution<a id="14224"></a>.</p>
        <p>These parameters<a id="15028"></a> must be stored with<a id="14337"></a>  any  digital  sound<a id="14922"></a>  recording<a id="14694"></a> medium and<a id="14245"></a> retrieved by the tools that play those sounds. To be able to<a id="14453"></a> play such a file, we must receive not only the data<a id="14409"></a> stream, but also information indicating the sample frequency<a id="14578"></a>,<a id="14168"></a> <code>Fs</code>, and<a id="14246"></a> the word size<a id="15034"></a>.</p>
    </div>
  </div>

  <div class="chp-section" data-sect-num="3" data-sect-name="Implementation">
     <!-- Implementation -->
    <h2 id="14_3">14.3	Implementation</h2>
     <!--[MAJOR REWRITE REQUIRED]-->
     <div class="container">
        <p>MATLAB<a id="14401"></a> offers a number of<a id="14718"></a> tools for<a id="15048"></a> reading<a id="14219"></a> sound<a id="14923"></a> files: <code>audioread(<a id="14136"></a>...)</code>, for<a id="15049"></a> example<a id="14891"></a>. This function<a id="14176"></a> returns two variables: a vector of<a id="14719"></a> sound<a id="14924"></a> values and<a id="14247"></a> the sampling frequency<a id="14579"></a> in Hz (samples per second).</p>
        <p>To play a sound<a id="14925"></a> file, MATLAB<a id="14402"></a> provides the function<a id="14177"></a> <code>sound(<a id="14214"></a>data<a id="14410"></a>, rate)</code> where <code>data<a id="14411"></a></code> is the vector of<a id="14720"></a> sound<a id="14926"></a> values, and<a id="14248"></a> <code>rate</code> is the playback<a id="14673"></a> frequency<a id="14580"></a>,<a id="14169"></a> usually the frequency<a id="14581"></a> at which the sound<a id="14927"></a> values were recorded. We will see that the function<a id="14178"></a> <code>sound(<a id="14215"></a>...)</code> passes the data<a id="14412"></a> directly to<a id="14454"></a> the computer’s sound<a id="14928"></a> card, but different implementations will manage the behavior of<a id="14721"></a> the software that plays the sound<a id="14929"></a> in one of<a id="14722"></a> two ways.</p>
        <p><i>Blocking vs. Non<a id="14380"></a>-blocking:</i> "Blocking" refers to<a id="14455"></a> the behavior of<a id="14723"></a> your system after you have called the <code>sound(<a id="14216"></a>...)</code> function<a id="14179"></a> to<a id="14456"></a> play a sound<a id="14930"></a>. Blocking players will not return control to<a id="14457"></a> the code playing the sound<a id="14931"></a> until the sound<a id="14932"></a> has completed. This will allow only one sound<a id="14933"></a> to<a id="14458"></a> be played from<a id="14198"></a> an application at a time. Non<a id="14381"></a>-blocking players will not wait for<a id="15050"></a> the sound<a id="14934"></a> card to<a id="14459"></a> finish playing the sound<a id="14935"></a>, so multiple calls to<a id="14460"></a> the <code>sound(<a id="14217"></a>...)</code> function<a id="14180"></a> will overlay different sounds. You will need to<a id="14461"></a> experiment with<a id="14338"></a> your particular system to<a id="14462"></a> determine whether it blocks or not.</p>
    </div>
     <!--Put these online??A number of .wav files are included on the book’s Companion Web site to demonstrate many aspects of sound files.<-->
   </div>

   <div class="chp-section" data-sect-num="4" data-sect-name="Time Domain Operations">
     <!-- Time Domain Operations -->
    <h2 id="14_4">14.4	Time Domain Operations</h2>
    <div class="container">
        <p>First, we consider three kinds of<a id="14724"></a> operations<a id="14665"></a> on<a id="14382"></a> sound<a id="14936"></a> files in the time domain: slicing<a id="15016"></a>, playback<a id="14674"></a> frequency<a id="14582"></a> changes, and<a id="14249"></a> sound<a id="14937"></a> file frequency<a id="14583"></a> changes.</p>
    </div>

    <div class="chp-subsection" data-sub-num="2" data-sub-name="Slicing and Concatenating Sounds">
       <!-- Slicing and Concatenating Sound -->
      <h3 id="14_4_1">14.4.1 Slicing and<a id="14250"></a> Concatenating Sound</h3>
      <div class="container">
          <div class="container clearfix">
              <div class="float-sm-right card">
                  <img src="..\Images\Fig_14_2.JPG" alt="Figure 14.2" class="fig card-img">
                  <p class="figure-name card-title">Figure<a id="15077"></a> 14.2: Gone With the Wind Speech</p>
              </div>
              <p>Consider the problem of<a id="14725"></a> constructing<a id="15017"></a> comedic sayings by choosing and<a id="14251"></a> assembling words from<a id="14199"></a> published speeches. One example<a id="14892"></a> of<a id="14726"></a> a speech clip is "Frankly, my dear..." from<a id="14200"></a> <em>Gone with<a id="14339"></a> the Wind</em>. Listing 14.1 describes the process of<a id="14727"></a> assembling parts of<a id="14728"></a> this speech into a semi-coherent conversation.</p>
              <p>In Listing 14.1, we first read and<a id="14252"></a> play the sound<a id="14938"></a> from<a id="14201"></a> the "frankly, my dear..." speech; the plotted data<a id="14413"></a> can be seen in Figure<a id="15078"></a> 14.2. Then, we play it louder by increasing the amplitude and<a id="14253"></a> then play it softer by decreasing the amplitude. It is then played faster by dropping half the data<a id="14414"></a> and<a id="14254"></a> then played slower by reducing the playback<a id="14675"></a> frequency<a id="14584"></a>. Then, all of<a id="14729"></a> the speech pieces are pasted together to<a id="14463"></a> construct the final sound<a id="14939"></a> clip.</p>
          </div>
          <div class="row">
              <div class="col-sm-6">
                  <audio controls><source src="../audio/sp_givdamn2.wav" type="audio/wav" />"Frankly, my dear..." speech</audio>
                  <p class="figure-name">"Frankly, my dear..." speech</p>
              </div>
              <div class="col-sm-6">
                  <audio controls><source src="../audio/sp_bond.wav" type="audio/wav">Bond speech</audio>
                  <p class="figure-name">Bond speech</p>
              </div>
      	</div>
          <div class="row">
              <div class="col-sm-6">
                  <audio controls><source src="../audio/sp_beam.wav" type="audio/wav">Beam speech</audio>
                  <p class="figure-name">Beam Speech</p>
              </div>
              <div class="col-sm-6">
                  <audio controls><source src="../audio/speech.wav" type="audio/wav">Combined speech</audio>
                  <p class="figure-name">Combined Speech</p>
              </div>
          </div>
          <div class="listing">#listing_14_1#</div>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="2" data-sub-name="Musical Background">
       <!-- Musical Background -->
      <h3 id="14_4_2">14.4.2	Musical Background</h3>
      <div class="container clearfix">
          <div class="float-sm-right card">
              <img src="..\Images\Fig_14_3.JPG" alt="Figure 14.3" class="fig card-img">
              <p class="figure-name card-title">Figure<a id="15079"></a> 14.3: Musical Notes</p>
          </div>
          <p>For good historical reasons, music<a id="14150"></a> is usually described graphically on<a id="14383"></a> a music<a id="14151"></a> score. The graphics describe for<a id="15051"></a> each note to<a id="14464"></a> be played its pitch and<a id="14255"></a> its duration, together with<a id="14340"></a> other notations indicating how to<a id="14465"></a> introduce expression and<a id="14256"></a> quality into the music<a id="14152"></a>. However, this graphical notation is not amenable to<a id="14466"></a> the simple representation of<a id="14730"></a> music<a id="14153"></a> we need for<a id="15052"></a> these experiments. Rather, we will use the representation illustrated in Figure<a id="15080"></a> 14.3. The right side of<a id="14731"></a> this figure shows a standard piano keyboard, the index of<a id="14732"></a> each white note, and<a id="14257"></a> the number of<a id="14733"></a> half steps necessary to<a id="14467"></a> achieve the pitch of<a id="14734"></a> each note. On the left side of<a id="14735"></a> the figure, we see the method to<a id="14468"></a> be used in this text<a id="15020"></a> to<a id="14469"></a> describe simple tunes. It will consist of<a id="14736"></a> an array<a id="14128"></a> with<a id="14341"></a> two columns and<a id="14258"></a> n rows, where n is the number of<a id="14737"></a> notes to<a id="14470"></a> be played for<a id="15053"></a> each tune. The first column is the key number to<a id="14471"></a> play, and<a id="14259"></a> the second column is the number of<a id="14738"></a> beats each note should be played.</p>
          <p>The example<a id="14893"></a> to<a id="14472"></a> follow in Listing 14.2 will manipulate the file <code>instr_piano.wav<a id="15035"></a></code> to<a id="14473"></a> produce a snippet of<a id="14739"></a> music<a id="14154"></a>. This file is a recording<a id="14695"></a> of<a id="14740"></a> a single note played on<a id="14384"></a> a piano. <!--Other files provided in the Companion Web site are the same note played on a variety of instruments.--> There are two ways to<a id="14474"></a> accomplish this, as follows:</p>
          <ol>
           <li>Playing each note at a different playback<a id="14676"></a> frequency<a id="14585"></a></li>
           <li>Stretching or shrinking<a id="14226"></a> each note to<a id="14475"></a> match the required note pitch and<a id="14260"></a> playing them all at the same playback<a id="14677"></a> frequency<a id="14586"></a></li>
          </ol>
          <p>The first way is easier to<a id="14476"></a> understand and<a id="14261"></a> code, but very inflexible; the second method is a little more difficult to<a id="14477"></a> implement, but completely extensible. Musically speaking, if a sound<a id="14940"></a> is played at twice its natural frequency<a id="14587"></a>,<a id="14170"></a> it is heard as one musical<a id="14425"></a> octave higher. When you play a scale<a id="14888"></a> by playing each white key in turn from<a id="14202"></a> one note to<a id="14478"></a> the next octave, there are 8 keys to<a id="14479"></a> play with<a id="14342"></a> 7 frequency<a id="14588"></a> changes: 5 whole note steps (those separated by a black note) and<a id="14262"></a> 2 half note steps, for<a id="15054"></a> a total of<a id="14741"></a> 12 half note steps. These 12 half steps are logarithmically divided where the frequency<a id="14589"></a> multiplier between half note steps is 2<sup>1/12</sup>.</p>
          <div class="row">
            <div class="col-sm-6">
              <audio controls><source src="../audio/instr_piano.wav" type="audio/wav">Piano Note</audio>
              <p class="figure-name">Piano Note</p>
            </div>
          </div>
          <div class="listing">#listing_14_2#</div>
          <div class="listing">#alt_Text/ramblinWreck#</div>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="3" data-sub-name="Changing Sound Frequency">
       <!-- Changing Sound Frequency -->
      <h3 id="14_4_3">14.4.3	Changing Sound Frequency</h3>
      <div class="container clearfix">
          <div class="float-sm-right card">
              <img src="..\Images\Fig_14_4.JPG" alt="Figure 14.4" class="fig card-img">
              <p class="figure-name card-title">Figure<a id="15081"></a> 14.4: Creating a Tune File</p>
          </div>
          <p>We will leave as an exercise for<a id="15055"></a> the reader the question of<a id="14742"></a> playing a tune by changing<a id="14431"></a> the playback<a id="14678"></a> frequency<a id="14590"></a> of<a id="14743"></a> each note, which is really never a practical thing to<a id="14480"></a> do, and<a id="14263"></a> concentrate on<a id="14385"></a> playing all the notes of<a id="14744"></a> a tune with<a id="14343"></a> the same playback<a id="14679"></a> frequency<a id="14591"></a>. This allows the different notes to<a id="14481"></a> be copied into a single sound<a id="14941"></a> file and<a id="14264"></a> saved to<a id="14482"></a> be played back on<a id="14386"></a> any digital sound<a id="14942"></a> system.</p>
          <p>In order to<a id="14483"></a> change the perceived note frequency<a id="14592"></a> without changing<a id="14432"></a> the playback<a id="14680"></a> frequency<a id="14593"></a>,<a id="14171"></a> we have to<a id="14484"></a> change the number of<a id="14745"></a> data<a id="14415"></a> samples in the original data<a id="14416"></a> file much as we stretched or shrunk an image<a id="14698"></a> in Section 13.4.1.</p>
          <p><b>Play a Scale</b> Listing 14.2 shows a script that uses this capability to<a id="14485"></a> play the C Major scale<a id="14889"></a> (all white notes) on<a id="14387"></a> the piano. It repeatedly shortens the vector to<a id="14486"></a> increase the frequency<a id="14594"></a> of<a id="14746"></a> the note played.</p>
          <p><b>Play a Simple Tune</b> We now write a script to<a id="14487"></a> build a playable <code>.wav<a id="15036"></a></code> file using the note shrinking<a id="14227"></a> technique, also shown in Listing 14.2. It reads in the script <code>ramblinWreck</code> to<a id="14488"></a> define the tune in which the first column of<a id="14747"></a> each cell<a id="14135"></a> array<a id="14129"></a> specifies the relative pitch (the note on<a id="14388"></a> teh scale<a id="14890"></a>) and<a id="14265"></a> the second the duration in "beats".</p>
          <p>The goal is to<a id="14489"></a> put the notes into a single sound<a id="14943"></a> array<a id="14130"></a> called <code>wreck</code>, as illustrated in Figure<a id="15082"></a> 14.4, rather than playing the notes "on<a id="14389"></a> the fly." For each part, or instrument, this is accomplished as follows:</p>
          <ul>
           <li>In the <code>play_part</code> function<a id="14181"></a>, create an empty<a id="14142"></a> array<a id="14131"></a>, <code>part</code>, of<a id="14748"></a> the appropriate length (the length of<a id="14749"></a> the original note plus the total number of<a id="14750"></a> beats in the song)</li>
           <li>Initialize <code>where</code> to<a id="14490"></a> store the first note at the start of<a id="14751"></a> the tune</li>
           <li>Iterate across the <code>part</code> definition array<a id="14132"></a> <code>score</code> with<a id="14344"></a> the following steps:
               <ul>
                   <li>In the <code>getPitch</code> function<a id="14182"></a>, start with<a id="14345"></a> the original <code>note</code></li>
                   <li>Get the power of<a id="14752"></a> the note to<a id="14491"></a> decide how many times to<a id="14492"></a> raise the note array<a id="14133"></a> by half a step</li>
                   <li>Raise the <code>power</code> to<a id="14493"></a> the right pitch and<a id="14266"></a> save it as <code>pitch</code></li>
                   <li>Add that <code>pitch</code> vector to<a id="14494"></a> the <code>part</code> vector, starting at <code>where</code></li>
                   <li>Move the <code>where</code> variable<a id="15030"></a> down the <code>part</code> vector a distance equivalent to<a id="14495"></a> the duration of<a id="14753"></a> that note</li>
               </ul>
           </li>
           <li>When all the parts have been added to<a id="14496"></a> the tune file, play the tune and<a id="14267"></a> save it as a <code>.wav<a id="15037"></a></code> file.</li>
          </ul>
      </div>
    </div>
  </div>

  <div class="chp-section" data-sect-num="5" data-sect-name="The Fast Fourier Transform">
    <!-- The Fast Fourier Transform -->
    <h2 id="14_5">14.5  The Fast<a id="14163"></a> Fourier Transform</h2>
    <div class="container">
        <p>Typically, the time history display of<a id="14754"></a> a sound<a id="14944"></a> shows you the amplitude of<a id="14755"></a> the sound<a id="14945"></a> as a function<a id="14183"></a> of<a id="14756"></a> time but makes no attempt at showing the frequency<a id="14595"></a> content. While this works for<a id="15056"></a> the exercises above, we are often more interested in the frequency<a id="14596"></a> content of<a id="14757"></a> a sound<a id="14946"></a> file, for<a id="15057"></a> which we need a different presentation—a spectrum display.</p>
    </div>

    <div class="chp-subsection" data-sub-num="1" data-sub-name="Background">
       <!-- Background -->
      <h3 id="14_5_1">14.5.1 Background</h3>
      <div class="container clearfix">
          <div class="float-sm-right card">
              <img src="..\Images\Fig_14_5.JPG" alt="Figure 14.5" class="fig card-img">
              <p class="figure-name card-title">Figure<a id="15083"></a> 14.5: A typical spectrum display</p>
          </div>
          <p>In general, a spectrum display shows the amount of<a id="14758"></a> sound<a id="14947"></a> energy in a given frequency<a id="14597"></a> band throughout the duration of<a id="14759"></a> the sound<a id="14948"></a> analyzed but ignores the time at which the sound<a id="14949"></a> at that frequency<a id="14598"></a> was generated. Many acoustic amplifiers (see Figure<a id="15084"></a> 14.5) include two features that allow you to<a id="14497"></a> customize the sound<a id="14950"></a> output:</p>
          <ul>
           <li>A spectral display that changes values as the sound<a id="14951"></a> is played, indicating the amount of<a id="14760"></a> sound<a id="14952"></a> energy (vertically) in different frequency<a id="14599"></a> bands (horizontally)</li>
           <li>Filter controls to<a id="14498"></a> change the relative amplification in different frequency<a id="14600"></a> bands</li>
          </ul>
          <div class="float-sm-right card">
              <img src="..\Images\Fig_14_6.JPG" alt="Figure 14.6" class="fig card-img">
              <p class="figure-name card-title">Figure<a id="15085"></a> 14.6: Mechanics of<a id="14761"></a> the Fourier Transform</p>
          </div>
          <p> In the following paragraphs, we will consider only the analysis of<a id="14762"></a> the sound<a id="14953"></a> frequency<a id="14601"></a> content. The ability to<a id="14499"></a> reshape the sound<a id="14954"></a> frequency<a id="14602"></a> content as the sound<a id="14955"></a> plays is beyond the scope of<a id="14763"></a> this text<a id="15021"></a>.</p>
          <p>To achieve the motion of<a id="14764"></a> the spectrum display, software to<a id="14500"></a> analyze a segment of<a id="14765"></a> the sound<a id="14956"></a> file runs periodically and<a id="14268"></a> updates the spectrum display. Typically, perhaps 20 times a second, 1/20th second of<a id="14766"></a> sound<a id="14957"></a> file is analyzed and<a id="14269"></a> transformed. The software used for<a id="15058"></a> this conversion is known as the Fourier transform.</p>
          <p>While the mathematics of<a id="14767"></a> the Fourier transform is beyond the scope of<a id="14768"></a> this book, we can make use of<a id="14769"></a> the tools it offers without concerning ourselves with<a id="14346"></a> the details. There are a number of<a id="14770"></a> implementations of<a id="14771"></a> this transform; perhaps the most commonly used is the Fast<a id="14164"></a> Fourier Transform (FFT).  The  FFT  uses  clever  matrix<a id="14424"></a>  manipulations  to<a id="14501"></a>  optimize  the algorithm<a id="14126"></a> needed to<a id="14502"></a> generate the forward<a id="14167"></a> (time to<a id="14503"></a> frequency<a id="14603"></a>) and<a id="14270"></a> reverse (frequency to<a id="14504"></a> time) transforms.</p>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="2" data-sub-name="Implementation">
       <!-- Implementation -->
      <h3 id="14_5_2">14.5.2	Implementation</h3>
      <div class="container clearfix">
          <p>Figure<a id="15086"></a> 14.6 illustrates the overall process of<a id="14772"></a> transforming between the time domain and<a id="14271"></a> frequency<a id="14604"></a> domain. It starts with<a id="14347"></a> a simple sound<a id="14958"></a> file, a vector of<a id="14773"></a> N sound<a id="14959"></a> values in the range (−1.0 to<a id="14505"></a> 1.0), which, if played back at a sample frequency<a id="14605"></a> <code>Fs</code> samples per second, reproduces the sound<a id="14960"></a>. The parameters<a id="15029"></a> of<a id="14774"></a> interest for<a id="15059"></a> characterizing the time trace are:</p>
          <table class="table">
           <tr>
               <td><code>N</code></td>
               <td>the number of<a id="14775"></a> samples</td>
           </tr>
           <tr>
               <td><code>F<sub>s</sub></code></td>
               <td>the sampling frequency<a id="14606"></a></td>
           </tr>
           <tr>
               <td><code>&<a id="14666"></a>Delta;t</code></td>
               <td>the time between samples, computed as <code>1/Fs</code></td>
           </tr>
           <tr>
               <td><code>T<sub>max</sub></code></td>
               <td>the maximum time is N x &<a id="14667"></a>Delta;t</td>
           </tr>
          </table>
          <p>The FFT consumes a file describing the time history of<a id="14776"></a> the sound<a id="14961"></a> sampled at regular intervals &<a id="14668"></a>Delta;t and<a id="14272"></a> produces a frequency<a id="14607"></a> spectrum with<a id="14348"></a> a corresponding set of<a id="14777"></a> characteristics. The frequency<a id="14608"></a> spectrum consists of<a id="14778"></a> the same number, <code>N</code>, of<a id="14779"></a> data<a id="14417"></a> points, each of<a id="14780"></a> which is a complex value<a id="15022"></a> with<a id="14349"></a> real and<a id="14273"></a> imaginary parts. (While many displays actually plot the magnitude of<a id="14781"></a> the spectrum values, to<a id="14506"></a> accomplish the inverse transform, the complex values must be retained.) The frequency<a id="14609"></a> values are "folded" on<a id="14390"></a> the plot so that zero frequency<a id="14610"></a> occurs at either end<a id="14143"></a> of<a id="14782"></a> the spectrum, and<a id="14274"></a> the maximum frequency<a id="14611"></a> occurs in the middle, at spectrum data<a id="14418"></a> point <code>N/2</code>.</p>
          <p>The equivalent characteristics for<a id="15060"></a> the spectrum data<a id="14419"></a> are as follows:</p>
          <table class="table">
           <tr>
               <td><code>N</code></td>
               <td>the number of<a id="14783"></a> samples</td>
           </tr>
           <tr>
               <td><code>&<a id="14669"></a>Delta;f</code></td>
               <td>the frequency<a id="14612"></a> difference between samples, computed as <code>1/T<sub>max</sub></code></td>
           </tr>
           <tr>
               <td><code>F<sub>max</sub></code></td>
               <td>the frequency<a id="14613"></a> value<a id="15023"></a> at the end<a id="14144"></a> of<a id="14784"></a> the plot, is <code>N x &<a id="14670"></a>Delta;f</code> However, since the mathematics force this frequency<a id="14614"></a> to<a id="14507"></a> actually replicate the beginning frequency<a id="14615"></a>,<a id="14172"></a> the maximum effective frequency<a id="14616"></a> actually occurs at the mid-point with<a id="14350"></a> value<a id="15024"></a> <code>F<sub>max</sub>/2</code>.</td>
           </tr>
          </table>
          <div class="float-sm-right card technical-insights">
              <p class="card-title">Technical Insight 14.2</p>
              <p class="card-text">The fact that the actual maximum frequency<a id="14617"></a> is half of<a id="14785"></a> the sampling frequency<a id="14618"></a> is consistent with<a id="14351"></a> the Nyquist criterion that the maximum frequency<a id="14619"></a> you can discern with<a id="14352"></a> digital sampling is half the sampling frequency<a id="14620"></a>.</p>
          </div>
          <p>The FFT is mechanized using the function<a id="14184"></a> <code>fft(<a id="14166"></a>...)</code>, which consumes the time history and<a id="14275"></a> produces the complex spectrum file. The inverse FFT  function<a id="14185"></a>, <code>ifft(<a id="14213"></a>...)</code>,  takes  a spectrum array<a id="14134"></a> and<a id="14276"></a> reconstructs the time history. This pair of<a id="14786"></a> functions<a id="15018"></a> provides a powerful set of<a id="14787"></a> tools for<a id="15061"></a> manipulating sound<a id="14962"></a> files.</p>
      </div>
    </div>

    <div class="chp-subsection" data-sub-num="3" data-sub-name="Simple Spectral Analysis">
       <!-- Simple Spectral Analysis -->
      <h3 id="14_5_3">14.5.3	Simple Spectral Analysis</h3>
      <div class="container clearfix">
          <div class="float-sm-right card">
              <img src="..\Images\Fig_14_7.JPG" alt="Figure 14.7" class="fig card-img">
              <p class="figure-name card-title">Figure<a id="15087"></a> 14.7: FFT of<a id="14788"></a> a sine wave</p>
          </div>
          <p>Listing 14.3 illustrates a script that creates 10 seconds of<a id="14789"></a> an 8 Hz sine wave, plots<a id="14681"></a> the first second of<a id="14790"></a> it, performs the FFT, and<a id="14277"></a> plots<a id="14682"></a> the real and<a id="14278"></a> imaginary parts of<a id="14791"></a> the spectrum. Notice the following:</p>
          <ul>
           <li>A sine wave in the time domain transforms to<a id="14508"></a> a line in the frequency<a id="14621"></a> domain because all its energy is concentrated at that frequency<a id="14622"></a>—8 Hz in this example<a id="14894"></a>.</li>
           <li>Since the FFT is a linear<a id="14331"></a> process, multiple sine or cosine waves added together at different frequencies have additive effects in the spectrum.</li>
           <li>The resulting spectrum is complex (with real and<a id="14279"></a> imaginary parts) and<a id="14280"></a> symmetrical about its center, the point of<a id="14792"></a> maximum frequency<a id="14623"></a>. On the plot, of<a id="14793"></a> course, one cannot make the frequency<a id="14624"></a> axis labels reduce from<a id="14203"></a> the center to<a id="14509"></a> the end<a id="14145"></a>.</li>
           <li>The real part of<a id="14794"></a> the spectrum is mirrored about the center; the imaginary part is mirrored and<a id="14281"></a> inverted (the complex conjugate of<a id="14795"></a> the original data<a id="14420"></a>).</li>
           <li>The phase of<a id="14796"></a> the complex spectrum retains the position of<a id="14797"></a> the sine wave in the time domain—it would be totally real for<a id="15062"></a> a cosine wave symmetrically placed in time and<a id="14282"></a> totally imaginary for<a id="15063"></a> a sine wave in the same relationship.</li>
          </ul>
          <p>The script in Listing 14.3 creates three sub-plots<a id="14683"></a>: the original sine wave and<a id="14283"></a> then the amplitude and<a id="14284"></a> phase of<a id="14798"></a> the spectrum.</p>
          <p>Figure<a id="15088"></a> 14.7 shows the result from<a id="14204"></a> running<a id="14904"></a> this script. It confirms the earlier statement that the real part of<a id="14799"></a> the spectrum is mirrored about the center frequency<a id="14625"></a>,<a id="14173"></a> and<a id="14285"></a> the imaginary part is mirrored and<a id="14286"></a> inverted.</p>
          <div class="listing">#listing_14_3#</div>
      </div>
    </div>
  </div>

  <div class="chp-section" data-sect-num="6" data-sect-name="Frequency Domain Operations">
     <!-- Frequency Domain Operations -->
    <h2 id="14_6">14.6  Frequency Domain Operations</h2>
    <div class="container">
      <p>This section is intended to<a id="14510"></a> set up the process of<a id="14800"></a> building<a id="14137"></a> a synthesizer<a id="14160"></a> that will replicate with<a id="14353"></a> a reasonable level of<a id="14801"></a> fidelity the sound<a id="14963"></a> of<a id="14802"></a> a piano without resorting, as we did above, to<a id="14511"></a> reading<a id="14220"></a> and<a id="14287"></a> manipulating a piano time history. To do this, we must understand the basics of<a id="14803"></a> the frequency<a id="14626"></a> spectrum of<a id="14804"></a> the instrument and<a id="14288"></a> shaping its time history.</p>
    	<p>As a typical example<a id="14895"></a> of<a id="14805"></a> operating<a id="14572"></a> in the frequency<a id="14627"></a> domain, we will consider analyzing the spectral quality of<a id="14806"></a> different musical<a id="14426"></a> instruments. The intent of<a id="14807"></a> this section is to<a id="14512"></a> develop a plot showing the spectra of<a id="14808"></a> a selection of<a id="14809"></a> different musical<a id="14427"></a> instruments. <!--We will first build a function that plots the spectrum for a single instrument and then build the script to create all the plots.--> Listing 14.4 shows a function<a id="14186"></a> that reads the .wav<a id="15038"></a> file of<a id="14810"></a> an instrument. The author is deeply indebted to<a id="14513"></a> the University of<a id="14811"></a> Miami's Audio and<a id="14289"></a> Signal Processing Laboratory who<a id="15074"></a> gave permission to<a id="14514"></a> use their musical<a id="14428"></a> instrument sound<a id="14964"></a> collection.  This provided us with<a id="14354"></a> a series of<a id="14812"></a> sound<a id="14965"></a> traces recording<a id="14696"></a> different instruments.  All were recorded in a quiet room playing the same musical<a id="14429"></a> note giving us clean, pure recordings of<a id="14813"></a> a large number of<a id="14814"></a> instruments. http://chronos.ece.miami.edu/~dasp/samples/samples.html. <!--All the instruments are carefully playing a note at about 260 Hz.--></p>
      <div class="row">
          <div class="col-sm-6">
              <audio controls><source src="../audio/instr_violin.wav" type="audio/wav">Violin Frequency Spectrum</audio>
              <p class="figure-name">Violin Frequency Spectrum</p>
          </div>
          <div class="col-sm-6">
              <audio controls><source src="../audio/instr_tpt.wav" type="audio/wav">Trumpet Frequency Spectrum</audio>
              <p class="figure-name">Trumpet Frequency Spectrum</p>
          </div>
      </div>
      <div class="row">
        <div class="col-sm-6">
            <audio controls><source src="../audio/trainwhistle.wav" type="audio/wav">Train Whistle Frequency Spectrum</audio>
            <p class="figure-name">Train Whistle Frequency Spectrum</p>
        </div>
      </div>
      <div class="container clearfix">
          <div class="float-sm-right card">
              <img src="..\Images\Fig_14_8.JPG" alt="Figure 14.8" class="fig card-img">
              <p class="figure-name card-title">Figure<a id="15089"></a> 14.8: Instrument Spectra</p>
          </div>
          <p>The results are shown in Figure<a id="15090"></a> 14.8. It is interesting to<a id="14515"></a> notice the following:</p>
          <ul>
            <li>None of<a id="14815"></a> the instruments produce a pure tone. The lowest frequency<a id="14628"></a> at which there is energy is usually called the fundamental frequency<a id="14629"></a>,<a id="14174"></a> and<a id="14290"></a> successive peaks to<a id="14516"></a> the right at multiples of<a id="14816"></a> the fundamental frequency<a id="14630"></a> are referred to<a id="14517"></a>, for<a id="15064"></a> example<a id="14896"></a>, as the first, second, and<a id="14291"></a> third harmonics.</li>
            <li>Several instruments have much more energy in the harmonics than in the fundamental frequency<a id="14631"></a>.</li>
            <li>"Families" of<a id="14817"></a> instruments have similar spectral shapes—the strings, for<a id="15065"></a> example<a id="14897"></a>, have strong fundamental and<a id="14292"></a> second harmonic energy. In principle, these characteristic spectral "signatures" can be used to<a id="14518"></a> synthesize the sound<a id="14966"></a> of<a id="14818"></a> instruments, and<a id="14293"></a> even to<a id="14519"></a> identify individual instruments when played in groups.</li>
          </ul>
      </div>
      <div class="listing">#listing_14_4#</div>
    </div>

      <div class="chp-subsection" data-sub-num="1" data-sub-name="Details of the Spectral Data">
      <h3 id="14_6_1">14.6.1 Details of<a id="14819"></a> the Spectral Data</h3>
          <div class="container clearfix">
              <div class="float-sm-right card">
                  <img src="..\Images\Fig_14_9.JPG" alt="Figure 14.9" class="fig card-img">
                  <p class="figure-name card-title">Figure<a id="15091"></a> 14.9: Instrument Spectra</p>
              </div>
              <p>We will now look carefully at the characteristics of<a id="14820"></a> the Frequency Spectrum using the code in Listing 14.5.  The first view we create is the spectrum plot of<a id="14821"></a> a sine wave at 261.6 Hz which musicians would recognize as Middle C.  Since all the sound<a id="14967"></a> energy is at that one frequency<a id="14632"></a>,<a id="14175"></a> the spectrum is a vertical line at 261.6 Hz.  The scaling on<a id="14391"></a> the vertical axis is complicated and<a id="14294"></a> irrelevant to<a id="14520"></a> this discussion. Consider the vertical axis to<a id="14521"></a> show the relative amounts of<a id="14822"></a> energy as a function<a id="14187"></a> of<a id="14823"></a> frequency<a id="14633"></a>. Note that the FFT function<a id="14188"></a> is assuming that the sound<a id="14968"></a> being analyzed is the sum of<a id="14824"></a> a number of<a id="14825"></a> sine waves at different frequencies.  The task of<a id="14826"></a> the FFT is to<a id="14522"></a> separate out and<a id="14295"></a> display the sound<a id="14969"></a> energy at each frequency<a id="14634"></a>.  In this example<a id="14898"></a>, there is only one frequency<a id="14635"></a>.</p>
          </div>
          <div class="container clearfix">
              <div class="float-sm-right card">
                  <img src="..\Images\Fig_14_10.JPG" alt="Figure 14.10" class="fig card-img">
                  <p class="figure-name card-title">Figure<a id="15092"></a> 14.10: Spectrum of<a id="14827"></a> a trumpet</p>
              </div>
              <p>In this next example<a id="14899"></a>, we will plot the absolute values of<a id="14828"></a> the frequency<a id="14636"></a> spectrum of<a id="14829"></a> a trumpet playing the same note at 261.6 Hz. Notice some interesting characteristics of<a id="14830"></a> this spectrum:
          		<ul>
            		<li>There is some energy at 261.6 Hz (normally called the "fundamental frequency<a id="14637"></a>" - the note intended to<a id="14523"></a> to<a id="14524"></a> be played by the musician.)  </li>
            		<li>However, the bulk of<a id="14831"></a> the sound<a id="14970"></a> energy is at higher frequencies.</li>
            		<li>"Musical" sounds in general are composed of<a id="14832"></a> energy at the fundamental frequency<a id="14638"></a> combined with<a id="14355"></a> energy at integer multipliers of<a id="14833"></a> the fundamental frequency<a id="14639"></a> referred to<a id="14525"></a> as the "harmonics." Contrast this with<a id="14356"></a> the "dirty" looking frequency<a id="14640"></a> spectrum of<a id="14834"></a> the train whistle in Figure<a id="15093"></a> 14.8 that is not normally classed as "musical<a id="14430"></a>"</li>
                <li>		Notice with<a id="14357"></a> the trumpet that the maximum energy is in the 4th harmonic and<a id="14296"></a> the first ten harmonics all have more energy than the fundamental.  This gives the trumpet its "brilliant" sound<a id="14971"></a>.</li>
          		</ul></p>
          </div>
          <div class="container clearfix">
              <div class="float-sm-right card">
                  <img src="..\Images\Fig_14_11.JPG" alt="Figure 14.11" class="fig card-img">
                  <p class="figure-name card-title">Figure<a id="15094"></a> 14.11: The Spectrum is actually complex</p>
              </div>
              <p>In this next example<a id="14900"></a>, we will plot the real and<a id="14297"></a> imaginary parts of<a id="14835"></a> the same trumpet frequency<a id="14641"></a> spectrum. Notice that the physical<a id="14159"></a> mechanics of<a id="14836"></a> the shape of<a id="14837"></a> the trumpet has created frequency<a id="14642"></a> spectrum values that are "out of<a id="14838"></a> phase" with<a id="14358"></a> other spectrum values.  We will not really be concerned with<a id="14359"></a> this except to<a id="14526"></a> observe that we need to<a id="14527"></a> reproduce the phase as well as the magnitude of<a id="14839"></a> the energy if we are to<a id="14528"></a> produce a faithful reproduction of<a id="14840"></a> the spectrum of<a id="14841"></a> an instrument.</p>
          </div>
          <div class="listing">#listing_14_5#</div>
        </div>

        <div class="chp-subsection" data-sub-num="2" data-sub-name="Notes fading with time">
          <h3 id="14_6_2">14.6.2 Notes fading with<a id="14360"></a> time</h3>
          <div class="container clearfix">
              <div class="float-sm-right card">
                  <img src="..\Images\Fig_14_12.JPG" alt="Figure 14.12" class="fig card-img">
                  <p class="figure-name card-title">Figure<a id="15095"></a> 14.12: trumpet time history</p>
              </div>
              <p>Many instruments have a relatively constant amplitude when played.  For example<a id="14901"></a>, a trumpet's amplitude is controlled by the musician's breath, and<a id="14298"></a> could be assumed to<a id="14529"></a> be constant over the duration of<a id="14842"></a> the note as illustrated in Figure<a id="15096"></a> 14.12. If this is the case<a id="14138"></a>, everything necessary to<a id="14530"></a> make a synthesizer<a id="14161"></a> has been accomplished. Listing 14.6 was used to<a id="14531"></a> generate this figure, together with<a id="14361"></a> the frequency<a id="14643"></a> spectrum not repeated here.</p>
          </div>
          <div class="listing">#listing_14_6#</div>
          <div class="container clearfix">
              <div class="float-sm-right card">
                  <img src="..\Images\Fig_14_13.JPG" alt="Figure 14.13" class="fig card-img">
                  <p class="figure-name card-title">Figure<a id="15097"></a> 14.13: piano time history</p>
              </div>
              <p>Some instruments, however, are played by striking a string, for<a id="15066"></a> example<a id="14902"></a>, and<a id="14299"></a> the allowing the reverberation of<a id="14843"></a> the sound<a id="14972"></a> to<a id="14532"></a> continue<a id="14139"></a>, gradually fading over time.  Figure<a id="15098"></a> 14.13 illustrates the changes over time when a piano note is played. In order to<a id="14533"></a> apply a profile over time to<a id="14534"></a> our synthetic piano note, we need to<a id="14535"></a> reach ahead to<a id="14536"></a> Chapter 15 to<a id="14537"></a> use curve<a id="14566"></a> fitting<a id="14140"></a> to<a id="14538"></a> model the shape of<a id="14844"></a> the sound<a id="14973"></a> decay.  We will merely report the general steps here and<a id="14300"></a> refer the reader to<a id="14539"></a> section 15.2 for<a id="15067"></a> the details.
              <ul>
                <li>In general, we need first to<a id="14540"></a> define some data<a id="14421"></a> points shown as red plus signs that define the decay.</li>
                <li>We then use the tools of<a id="14845"></a> chapter 15 to<a id="14541"></a> compute a small number of<a id="14846"></a> coefficients that force a polynomial<a id="14141"></a> curve<a id="14567"></a> to<a id="14542"></a> best fit these data<a id="14422"></a> points shown as the cyan colored curve<a id="14568"></a>.  </li>
                <li>Finally, we generate that curve<a id="14569"></a> and<a id="14301"></a> multiply the sound<a id="14974"></a> at each sample point by the interpolated value<a id="15025"></a> of<a id="14847"></a> that curve<a id="14570"></a>.</li>
              </ul>
            </p>
          </div>
          <div class="listing">#listing_14_7#</div>
        </div>
      </div>


    <div class="chp-section" data-sect-num="7" data-sect-name="Engineering Example - Music Synthesizer">
       <!-- Engineering Example -->
      <h2 id="14_7">14.7 Engineering Example - Music Synthesizer</h2>
      <div class="container">
          <p>A music<a id="14155"></a> synthesizer<a id="14162"></a> is an electronic instrument with<a id="14362"></a> a piano style keyboard that is able to<a id="14543"></a> simulate the sound<a id="14975"></a> of<a id="14848"></a> multiple instruments. Unlike the instrument sounds we have used so far, the instrument sounds are not stored as large time histories. Rather, they are stored as the Fourier coefficients  similar to<a id="14544"></a> those illustrated in Figure<a id="15099"></a> 14.11. The sound<a id="14976"></a> is then reconstructed by multiplying sin or cosine waves of<a id="14849"></a> the right frequency<a id="14644"></a> by the stored coefficients. For some instruments, this is sufficient. Other instruments such as pianos need to<a id="14545"></a> have the amplitude of<a id="14850"></a> the resulting sound<a id="14977"></a> modified to<a id="14546"></a> match a typical profile. Listings 14.8 illustrates a possible technique for<a id="15068"></a> extracting the most important Fourier coefficients from<a id="14205"></a> the piano sound<a id="14978"></a>. We would then apply the fading curve<a id="14571"></a> created in section 14.6.2 above to<a id="14547"></a> each note and<a id="14302"></a> create the music<a id="14156"></a> from<a id="14206"></a> the individual notes.</p>
          <div class="listing">#listing_14_8#</div>
          <div class="row">
              <div class="col-sm-6">
                  <audio controls><source src="..\audio\humoresque_1.wav" type="audio/wav">Anton Dvorak: "Humoresque"</audio>
                  <p class="figure-name">Anton Dvorak: "Humoresque"</p>
              </div>
          </div>
      </div>
    </div>

  <!-- Chapter Summary -->
  <h2>Chapter Summary</h2>
  <div class="container">
      <p>This chapter presented the following:</p>
      <ul>
          <li>Sounds are read with<a id="14363"></a> specific readers that provide a time history and<a id="14303"></a> sampling frequency<a id="14645"></a></p>
          <li>Sounds can be played through the computer’s sound<a id="14979"></a> system and<a id="14304"></a> saved to<a id="14548"></a> disk as a sound<a id="14980"></a> file ready for<a id="15069"></a> playing on<a id="14392"></a> any digital player</li>
          <li>We can slice and<a id="14305"></a> concatenate sounds to<a id="14549"></a> edit speeches and<a id="14306"></a> change the frequency<a id="14646"></a> of<a id="14851"></a> the sound<a id="14981"></a> to<a id="14550"></a> change its pitch</li>
          <li>We can analyze the frequency<a id="14647"></a> content of<a id="14852"></a> sound<a id="14982"></a> using the Fast<a id="14165"></a> Fourier Transform (FFT)</li>
          <li>We can modify the spectra by adding, deleting, or changing<a id="14433"></a> the sound<a id="14983"></a> levels at chosen frequencies under certain controlled conditions</li>
          <li>We can reconstruct a sound<a id="14984"></a> from<a id="14207"></a> the FFT coefficients.</li>
      </ul>
  </div>
<h2>Self Test</h2>
<div class="container">

Use the following questions to<a id="14551"></a> check your understanding of<a id="14853"></a> the material in this
chapter:
<h3>True or False</h3>
<ol>
<li>Playing a sound<a id="14985"></a> file at double the recorded sample frequency<a id="14648"></a> raises
its pitch by an octave.</li>
          <li>Removing every other sample from<a id="14208"></a> a sound<a id="14986"></a> file lowers the pitch by
an octave.</li>
          <li>The resolution<a id="14225"></a> of<a id="14854"></a> the recorded data<a id="14423"></a> has a significant effect on<a id="14393"></a> the
quality of<a id="14855"></a> the recording<a id="14697"></a>.</li>
          <li>After performing an FFT, the zero frequency<a id="14649"></a> occurs at either end<a id="14146"></a> of<a id="14856"></a>
the spectrum and<a id="14307"></a> the maximum frequency<a id="14650"></a> occurs in the middle.</li>
          <li>Since the mathematics of<a id="14857"></a> the FFT are linear<a id="14332"></a>, the spectrum of<a id="14858"></a> a sound<a id="14987"></a>
added in the time domain is also added in the frequency<a id="14651"></a> domain.</li>
</ol>
<h3>Fill in the Blanks</h3>
<ol>
<li>Sound pressure fluctuations have two attributes: their
_______________ and<a id="14308"></a> their _______________.</li>
          <li>Each word coming out of<a id="14859"></a> the _____________ or going into the
_______________ merely represents the _______________ on<a id="14394"></a> the
microphone at a point in time.</li>
          <li>The steps from<a id="14209"></a> one note to<a id="14552"></a> the next higher octave are divided into
_______________ increments: _______________ whole note steps and<a id="14309"></a>
_______________ half note steps, for<a id="15070"></a> a total of<a id="14860"></a> _______________ half
note steps.</li>
          <li>A spectrum display shows the amount of<a id="14861"></a> _______________ in a
given _______________ throughout the duration of<a id="14862"></a> the sound<a id="14988"></a>
analyzed.</li>
</ol>

<h3>Programming Projects</h3>
<ol>
<li>These are fundamental exercises with<a id="14364"></a> sound<a id="14989"></a> files. You should not
hard-code any of<a id="14863"></a> the answers for<a id="15071"></a> this problem, and<a id="14310"></a> you should not
need iteration<a id="14333"></a>.
<ol type="a">
<li>Select and<a id="14311"></a> read a suitable .wav<a id="15039"></a> file, and<a id="14312"></a> save the sound<a id="14990"></a> values
and<a id="14313"></a> sampling frequency<a id="14652"></a>.</li>
          <li>Create a new sound<a id="14991"></a> that has double the frequency<a id="14653"></a> of<a id="14864"></a> the original
sound<a id="14992"></a>, and<a id="14314"></a> store your answer in the variable<a id="15031"></a> sound<a id="14993"></a>_Double.</li>
          <li>Create a new sound<a id="14994"></a> that is the same as the original except that
the pitch is raised by five half tones. Store your answer in the
variable<a id="15032"></a> raised_pitch.</li>
          <li>We need a figure showing two views each of<a id="14865"></a> these three
sounds, created using subplot. <br>
In the left column, plot the
original sound<a id="14995"></a>, sound<a id="14996"></a>_Double, and<a id="14315"></a> raised_pitch, labeling each
plot accordingly.<br>
In the right column, plot the first quarter of<a id="14866"></a> the values of<a id="14867"></a> the
power spectrum of<a id="14868"></a> each sound<a id="14997"></a> with<a id="14365"></a> the proper frequency<a id="14654"></a> values
on<a id="14395"></a> the horizontal axis.</li>
          <li>Play each of<a id="14869"></a> the sounds in the following order: original sound<a id="14998"></a>,
sound<a id="14999"></a>_Double , and<a id="14316"></a> raised_pitch each at the original sampling
frequency<a id="14655"></a>.</li>
          </ol></li>
          <li>Write a function<a id="14189"></a> that will accept a string specifying a sound<a id="15000"></a> file and<a id="14317"></a>
do the following:
<ol type="a">
<li>Play back the sound<a id="15001"></a>..</li>
          <li>Plot the sound<a id="15002"></a> in the time domain, titling and<a id="14318"></a> labeling your plot
appropriately..</li>
          <li>Compute the frequency<a id="14656"></a> with<a id="14366"></a> the most energy in this file.
Validate your answer by plotting the lower quarter of<a id="14870"></a> the
frequencies of<a id="14871"></a> the Fourier Transform of<a id="14872"></a> the sound<a id="15003"></a>. Don<a id="14396"></a>'t forget
that the Fourier Transform is complex; you will need to<a id="14553"></a> reason
with<a id="14367"></a> and<a id="14319"></a> plot the absolute value<a id="15026"></a> of<a id="14873"></a> the spectrum..</li>
          <li>Test this function<a id="14190"></a> with<a id="14368"></a> suitable .wav<a id="15040"></a> files.</li>
		  </ol>
          <li>Write a function<a id="14191"></a> named plotSound that takes in the name of<a id="14874"></a> a sound<a id="15004"></a>
file and<a id="14320"></a> produces a 1 3 2 figure with<a id="14369"></a> two plots<a id="14684"></a>. The first plot should
be a plot of<a id="14875"></a> the sound<a id="15005"></a> in the time domain. The second plot should
be a plot of<a id="14876"></a> the sound<a id="15006"></a> in the frequency<a id="14657"></a> domain. Your function<a id="14192"></a>
should not return anything. Label the first plot 'Time Domain' and<a id="14321"></a>
label its axes appropriately. Label second plot 'Frequency Domain'
and<a id="14322"></a> label its axes appropriately.
The Time Domain plot should be an amplitude vs. time plot. For
simplicity make sure that your time vector starts at dt (delta time)
and<a id="14323"></a> goes to<a id="14554"></a> n*dt (t max ) where n is the number of<a id="14877"></a> samples.
<br>The Frequency Domain plot should be a power vs. frequency<a id="14658"></a> plot
where power is the absolute value<a id="15027"></a> of<a id="14878"></a> the FFT of<a id="14879"></a> the amplitude
values. For simplicity make sure that your frequency<a id="14659"></a> vector starts at
df (delta frequency<a id="14660"></a>) and<a id="14324"></a> goes to<a id="14555"></a> n*df (2*f max ).</li>
          <li>In this exercise, we will write a script to<a id="14556"></a> create an instrument sound<a id="15007"></a>
from<a id="14210"></a> scratch.
<ol type="a">
<li>Create a vector, t , of<a id="14880"></a> time values from<a id="14211"></a> 0 to<a id="14557"></a> 2 seconds with<a id="14370"></a> length
40,000 samples.</li>
          <li>Convert the frequency<a id="14661"></a> of<a id="14881"></a> middle C (261.6 Hz) to<a id="14558"></a> v radians per
second.</li>
          <li>Compute a sound<a id="15008"></a> sample as cos(vt) over the range of<a id="14882"></a> t in part a.</li>
          <li>Play that sound<a id="15009"></a> at a sample frequency<a id="14662"></a> of<a id="14883"></a> 20,000, and<a id="14325"></a> verify that it
sounds "about right."</li>
          <li>Perform the Fourier Transform on<a id="14397"></a> the sound<a id="15010"></a> vector, establish the
correct axis values, and<a id="14326"></a> prove that the sound<a id="15011"></a> is exactly Middle C.
</ol></li>
          <li>Write a function<a id="14193"></a> named playNote that takes in a string representing
a note on<a id="14398"></a> the piano. Your function<a id="14194"></a> should return a vector
representing the amplitude values of<a id="14884"></a> the note in addition to<a id="14559"></a> the
correct sampling frequency<a id="14663"></a> to<a id="14560"></a> be used to<a id="14561"></a> play it back. You should
do this by modifying the sound<a id="15012"></a> in the provided instr_piano.wav<a id="15041"></a> file
which is Middle C played on<a id="14399"></a> the piano. Note that the returned
sampling frequency<a id="14664"></a> should be the same as that in instr_piano..wav<a id="15042"></a> .
Here is a list of<a id="14885"></a> all the possible note names<a id="15033"></a> representing notes that
your function<a id="14195"></a> should work with<a id="14371"></a> and<a id="14327"></a> below that is the number of<a id="14886"></a>
half steps above/below the middle C for<a id="15072"></a> that note:
<table>
<tr><td >cn</td><td>cn#</td><td>dn</td><td>dn#</td><td>en</td><td>fn</td><td>fn#</td><td>gn</td><td>gn#</td><td>a(n+1)</td><td>a(n+1)#</td><td>b(n+1)</td><td>c(n+1)</td></tr>
<tr><td>-12</td><td>-11</td><td>-10</td><td>-9</td><td>-8</td><td>-7</td><td>-6</td><td>-5</td><td>-4</td><td>-3</td><td>-2</td><td>-1</td><td>0</td></tr>
</table>
where c4 is the middle C, c5 is 1 octave above it, and<a id="14328"></a> c3 is 1 octave
below it. Similarly, f5 is 1 octave higher than f4, etc. For example<a id="14903"></a>,
[y1 fs] = playNote('c5'); should return a vector such that
sound(<a id="14218"></a>y1, fs) should sound<a id="15013"></a> like middle C</li>
          <li>Finally, you will use these tools to<a id="14562"></a> play your favorite song.
		  <ol type = "a">
<li>Find the music<a id="14157"></a> for<a id="15073"></a> your favorite song, and<a id="14329"></a> translate it into the
symbology of<a id="14887"></a> Problem 14.5.</li>
          <li> Write a script that uses the playNote function<a id="14196"></a> to<a id="14563"></a> play your song
on<a id="14400"></a> the piano.</li>
          <li>Modify playNote to<a id="14564"></a> use your synthetic instrument from<a id="14212"></a> Problem
14.3, and<a id="14330"></a> save it as playSynthetic .</li>
          <li>Write a script that uses playSynthetic to<a id="14565"></a> play your song in
futuristic style.
</ol>
</ol>
</div>
</div>


</body>
</html>

