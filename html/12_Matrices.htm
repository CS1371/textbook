<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<html>

<head>
<title>12_Matrices</title>
<script async src="./javascript/index.js"></script>
<!-- include bootstrap -->
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"></script>
<!-- include stylesheets -->
<link rel="stylesheet" href="styles/styles.css" />
</head>


<body bgcolor="#ffffff">

<h1 align="center">Chapter 12: Matrices</h1>
<table align="center">
<tbody>
<tr>
<td><a href="11_Plotting.htm">previous</a></td>
<td><a href="Contents.htm">home</a></td>
<td><a href="13_Images.htm">next</a></td>
</tr>
</tbody>
</table>
<ul>
<li><a href="#12_1">12.1   Concept: Behavioral Abstraction</a>
<li><a href="#12_2">12.2  Matrix Operations</a>
<ul>
    <li><a href="#12_2_1">12.2.1  Matrix Multiplication</a>
    <li><a href="#12_2_2">12.2.2  Matrix Division</a>
    <li><a href="#12_2_3">12.2.3  Matrix Exponentiation</a>
</ul>
<li><a href="#12_3">12.3    Implementation</a>
<ul>
    <li><a href="#12_3_1">12.3.1  Matrix Multiplication</a>
    <li><a href="#12_3_2">12.3.2  Matrix Division</a>
</ul>
<li><a href="#12_4">12.4   Rotating Coordinates</a>
<ul>
    <li><a href="#12_4_1">12.4.1 2-D Rotation</a>
    <li><a href="#12_4_2">12.4.2 3-D Rotation</a>
</ul>
<li><a href="#12_5">12.5  Solving Simultaneous Linear   Equations</a>
<ul>
    <li><a href="#12_5_1">12.5.1  Intersecting Lines</a>
</ul>
<li><a href="#12_6">12.6   Engineering Examples</a>
<ul>
    <li><a href="#12_6_1">12.6.1 Ceramic Composition</a>
    <li><a href="#12_6_2">12.6.2 Analyzing an Electrical Circuit</a>
</ul>

<!-- Chapter Objectives -->
<h1>Chapter Objectives</h1>
<div class="container">
    <p>This chapter shows matrices as logical extensions of arrays. You will learn about two specialized operations performed with matrices: </p>
    <ul>
        <li>Multiplication for coordinate rotation</li>
        <li>Division for solving simultaneous equations</li>
    </ul>
</div>

<!-- Introduction -->
<h1>Introduction</h1>
<div class="container">
    <p>Although the matrix operations that are the subject of this chapter can be performed on pairs of vectors or arrays that meet certain criteria, when using these operations, we tend to refer to the data objects as matrices. In most mathematical discussions, the words "matrix" and "array" can be used interchangeably, and rightly so, because they store data in exactly the same form. Moreover, almost all of the operations we can perform on an array can also be performed on a matrix—logical operations, concatenation, slicing, and most of the arithmetic operations behave identically. The fact that some of the mathematical operations are defined differently gives us a chance to think about an important concept that is usually well hidden within the MATLAB language definition.</p>
</div>

<!-- Behavioral Abstration -->
<h2 id="12_1">12.1	Concept: Behavioral Abstraction</h2>
<div class="container">
    <p>Recall the following concepts:</p>
    <ul>
        <li><em>Abstraction</em> is the ability to ignore specific details and generalize the description of an entity</li>
        <li><em>Data abstraction</em> is the specific example of abstraction that we first considered whereby we could treat vectors of data (and later other collections like structures and arrays) as single entities rather than enumerating their elements individually</li>
        <li><em>Procedural abstraction</em> are functions that collect multiple operations into a form; once they are developed, we can overlook the specific details and treat them as a "black box," much as we treat built-in functions</li>
    </ul>
    <p>Behavioral abstraction combines data and procedural abstraction, encapsulating not only collections of data, but also the operations that are legal to perform on that data. One might argue that this is a new, irrelevant concept best ignored until “we just have to!” However, consider the rules we have had to establish for what we can and cannot do with data collections we have seen so far. For example, am I able to add two arrays together? Yes, but only if they have the same number of rows and columns, or if one of them is scalar. Can I add two character strings? Almost the same answer, except that each string is first converted to a numerical quantity and the result is a vector of numbers and not a string. Can I add two cell arrays? No.</p>
    <p>So at least some, and maybe all, data collections also "understand" the set of operations that are permitted on the data. This encapsulation of data and operations is the essence of behavioral abstraction. Therefore, we distinguish arrays from matrices not by the data they collect, but by the operations that are legal to perform on them.</p>
</div>

<!-- Matrix Operations -->
<h2 id="12_2">12.2	Matrix Operations</h2>
<div class="container">
    <p>The arithmetic operations that differ between arrays and matrices are multiplication, division, and exponentiation.</p>
</div>

<!-- Matrix Multiplication -->
<h3 id="12_2_1">12.2.1	Matrix Multiplication</h3>
<div class="container clearfix">
    <div class="float-sm-right card">
        <img src="Fig_12_1.JPG" alt="Figure 12.1" class="fig card-img">
        <p class="figure-name card-title">Figure 12.1: Matrix Dot Multiply</p>
    </div>
    <div class="float-sm-right card">
        <img src="Fig_12_2.JPG" alt="Figure 12.2" class="fig card-img">
        <p class="figure-name card-title">Figure 12.2: Mechanics of Matrix Multiplication</p>
    </div>
    <div class="float-sm-right card">
        <img src="Fig_12_3.JPG" alt="Figure 12.3" class="fig card-img">
        <p class="figure-name card-title">Figure 12.3: Matrix Multiplication</p>
    </div>
    <p>Previously, when we considered multiplying two arrays, we called this scalar multiplication, and it had the following typical array operation characteristics:</p>
    <ul>
        <li>Either the two arrays must be the same size, or one of them must be scalar</li>
        <li>The multiplication was indicated with the .* operator</li>
        <li>The result was an array with the same size as the larger original array</li>
        <li>Each element of the result was the product of the corresponding elements in the original two arrays</li>
    </ul>
    <p>This is best illustrated in Figure 12.1. Scalar division and exponentiation have the same constraints.</p>
    <p>Matrix multiplication, on the other hand, performed using the normal * operator, is an entirely different logical operation, as shown in Figure 12.2. The logical characteristics of matrix multiplication are as follows:</p>
    <ul>
        <li>The two matrices do not have to be the same size.</li>
        <ul>The requirements are either:
            <li>One of the matrices is a scalar, in which case the matrix operation reduces to a scalar multiply.</li>
            <li>The number of columns in the first matrix must equal the number of rows in the second. We refer to these as the <b>inner dimensions</b>. The result is a new matrix with the column count of the first matrix and the row count of the second.</li>
        </ul>
        <li>If, as illustrated, <code>A</code> is an <code>m x n</code> matrix and B is an <code>n x p</code> matrix, the result of <code>A * B</code> is an <code>m x p</code> matrix.</li>
        <li>The item at <code>(i, j)</code> in the result matrix is the sum of the scalar product of the <code>ith</code> row of <code>A</code> and the <code>jth</code> column of <code>B</code>.</li>
        <li>Whereas with scalar multiplication <code>A .* B</code> gives the same result as <code>B .* A</code>, this is not the case with matrix multiplication. In fact, if <code>A * B</code> works, <code>B * A</code> will not work unless both matrices are square, and even then the results are different. (Proof of this can be derived immediately from Figure 12.3 by eliminating the third row and column and exchanging <code>a</code> for <code>b</code>. All four terms of the result of <code>A * B</code> are different from <code>B * A</code>.)</li>
        <li>Whereas with scalar multiplication the original array <code>A</code> can be recovered by dividing the result by <code>B</code>, this is not the case with matrix multiplication unless both matrices are square.</li>
        <li>The <b>identity matrix</b>, sometimes given the symbol <code>I<sub>n</sub></code>, is a square matrix with <code>n</code> rows and <code>n</code> columns that is zero everywhere except on its major diagonal, which contains the value 1. In has the special property that when pre-multiplied by any matrix <code>A</code> with <code>n</code> columns, or post-multiplied with any matrix <code>A</code> with <code>n</code> rows, the result is <code>A</code>. We will need this property to derive matrix division below. (The built-in function <code>eye(...)</code> generates the identity matrix.)</li>
    </ul>
    <p>Figure 12.3 illustrates the mathematics for the case where a 3 x 2 matrix is multiplied by a 2 x 3 matrix, resulting in a 3 x 3 matrix.</p>
</div>

<!-- Matrix Division -->
<h3 id="12_2_2">12.2.2	Matrix Division</h3>
<div class="container">
    <p>Matrix division is the logical process of reversing the effects of a matrix multiplication. The goal is as follows: given <code>A<sub>nxn</sub></code>, <code>B<sub>nxp</sub></code>, and <code>C<sub>nxp</sub></code>, where <code>C = A * B</code>, we wish to define the mathematical equivalent of <code>C/A</code> that will result in <code>B</code>.</p>
    <p>Since <code>C = A * B</code>, we are actually searching for some matrix Kn3n by which we can multiply each side of the above equation:</p>
    <p><code>K * C = K * A * B</code></p>
    <p>This multiplication would accomplish the division we desire if <code>K * A</code> were to result in <code>I<sub>n</sub></code>, the identity matrix. If this were the case, pre-multiplying <code>C</code> by <code></code> would result in <code>I<sub>n</sub> * B</code>, or simply <code>B</code> by the definition of <code>In</code> above. The matrix <code>K</code> is referred to as the inverse of <code>A</code>, or <code>A<sup>-1</sup></code>. The algebra for computing this inverse is messy but well defined. In fact, Gaussian Elimination to solve linear simultaneous equations accomplishes the same thing. The MATLAB language defines both functions (<code>inv(A)</code>) and operators (“back divide,” \) that accomplish this. However, two things should be noted:</p>
    <ul>
        <li>This inverse does not exist for all matrices—if any two rows or columns of a matrix are linearly related, the matrix is <b><em>singular</em></b> and does not have an inverse</li>
        <li>Only non-singular, square matrices have an inverse (just as a set of linear equations is soluble only if there are as many equations as there are unknown variables)</li>
    </ul>
</div>

<!-- Matrix Exponentiation -->
<h3 id="12_2_3">12.2.3	Matrix  Exponentiation</h3>
<div class="container">
    <p>For completeness, we mention here that matrix operations include exponentiation. However, this does not suggest that one would encounter <code>A<sub>nxn</sub><sup>B<sub>nxn</sub></sup></code> in the scope of our applications. Rather, our usage of matrix exponentiation will be confined to <code>A<sup>k</sup></code> where <code>k</code> is any non-zero integer value. The result for positive <code>k</code> is accomplished by multiplying <code>A</code> by itself <code>k</code> times (using matrix multiplication). The result for negative <code>k</code> is accomplished by inverting <code>A<sup>-k</sup></code>. (There is, in fact, meaning in matrix exponentials with non- scalar exponents, but this involves advanced concepts with eigen values and eigenvectors and is beyond the scope of this text.)</p>
</div>

<!-- Implementation -->
<h2 id="12_3">12.3  Implementation</h2>
<div class="container">
    <p>In this section, we see how MATLAB implements matrix multiplication and division. However, since applications that require matrix exponentiation A<sup>k</sup> where k is anything but a scalar quantity are beyond the scope of this text, we will not look at its implementation in MATLAB. </p>
</div>

<!-- Matrix Multiplication -->
<h3 id="12_3_1">12.3.1	Matrix Multiplication</h3>
<div class="container">
    <p>Matrix multiplication is accomplished by using the “normal” multiplication symbol, as illustrated in Exercise 12.1.</p>
    <span class="exercise">Exercise 12.1</span>
</div>


<!-- Matrix Division -->
<h3 id="12_3_2">12.3.2	Matrix Division</h3>
<div class="container">
    <p>Matrix division is accomplished in a number of ways, all of which appear to work, but some give the wrong answer. Returning to the division problem described in Section 12.2.2, we know that <code>A</code> is a square matrix of side <code>n</code>, and <code>B</code> and <code>C</code> have <code>n</code> rows, and <code>C = A * B</code>. If we are actually given the matrices <code>A</code> and <code>B</code>, we can compute <code>B</code> in one of the following ways:</p>
    <ul>
        <li><code>B = inv(A) * C</code> — using the MATLAB <code>inv(...)</code> function to compute the inverse of <code>B</code></li>
        <li><code>B = A \ C</code> — "back dividing" <code>B</code> into <code>C</code> to produce the same result</li>
        <li><code>B = C / A</code> — apparently performing the same operation, but <em>giving different answers</em></li>
    </ul>
    <p>The order in which the matrix multiply is done affects the value of the result; therefore, care must be taken to ensure that the appropriate inversion or division is used. Study the results of Exercise 12.2 carefully.</p>
    <span class="exercise">Exercise 12.2</span>
</div>

<!-- Rotating Coordinates -->
<h2 id="12_4">12.4  Rotating Coordinates</h2>
<div class="container">
    <p>A common use for matrix multiplication is for rotating coordinates in two or three dimensions. Previously we have seen the ability to rotate a complete picture by changing the viewing angle. We can move and scale items on a plot by adding coordinate offsets or multiplying them by scalar quantities. However, frequently the need arises to rotate the coordinates of a graphical object by some angle. We can use matrix multiplication to rotate individual items in a picture in two or three dimensions.</p>
</div>

<!-- 2-D Rotation -->
<h3 id="12_4_1">12.4.1	2-D Rotation</h3>
<div class="container clearfix">
    <div class="float-sm-right card">
        <img src="Fig_12_4.JPG" alt="Figure 12.4" class="fig card-img">
        <p class="figure-name card-title">Figure 12.4: Rotating Cartesian Coordinates</p>
    </div>
    <p>The mathematics implementing rotation in two dimensions is relatively straightforward, as shown in Figure 12.4. If the original point location P is (x, y) and you wish to find the point P* (x*, y*) that is the result of rotating P by the angle &theta; about the origin of coordinates, the mathematics are as follows:</p>
    <p><code>x* = x cos&theta;  − y sin&theta;</code><br>
    <code>y* = x sin&theta;  + y cos&theta;</code></p>
    <p>which can be expressed as the matrix equation:</p>
    <p><code>P* = A * P</code></p>
    <p>where A is found by:</p>
    <p>A = [cos&theta; −sin&theta;; sin&theta; cos&theta;]</p>
    <p>To rotate the x-y coordinates of a graphic object in the x-y plane about some point, P, other than the origin, you would do as follows:</p>
    <ol>
        <li>Translate the object so that P is at the origin by subtracting P from all the object’s coordinates</li>
        <li>Perform the rotation by multiplying each coordinate by the rotation matrix shown above</li>
        <li>Translate the rotated object back to P by adding P to all the rotated coordinates</li>
    </ol>
    <p><b>Rotating a Line</b> Listing 12.1 illustrates a simple script to rotate a line about the origin.</p>
    <p>Figure 12.5 shows the plot resulting from this script.</p>
    <span class="listing">Listing 12.1</span>
    <div class="row">
        <div class="col-sm-6 card">
            <img src="Fig_12_5.JPG" alt="Figure 12.5" class="fig card-img">
            <p class="figure-name card-title">Figure 12.5: Line Rotations</p>
        </div>
        <div class="col-sm-6">
            <video controls class="fig"><source src="Fig_12_6.mp4" type="video/mp4">Figure 12.6</video>
            <p class="figure-name"><b>Figure 12.6: Stars</b></p>
        </div>
    </div>
    <p><b>Twinkling Stars</b> As a second example, consider the problem of simulating twinkling stars. One way to accomplish this is to draw two triangles for each star rotating in opposite directions. The script shown in Listing 12.2 accomplishes this.<p>
    <p>The results of this script are shown in Figure 12.6.</p>
    <span class="listing">Listing 12.2</span>
    <span class="listing">Listing 12.3</span>
</div>

<!-- 3-D Rotation -->
<h3 id="12_4_2">12.4.2	3-D Rotation</h3>
<div class="container clearfix">
    <p>The mathematics implementing rotation in three dimensions is a natural extension of the 2-D rotation case. We present here a simple way to make this extension. The 2-D rotation in Section 12.4.1 that rotates by the angle &theta; in the x-y plane is actually rotating about the z-axis. If P* and P are now 3-D coordinates, we can rotate P by an angle &theta; about the z-axis with the equation:</p>
    <p><code>P* = R<sub>z</sub> * P</code></p>
    <p>where R<sub>z</sub> is computed as</p>
    <p><code>R<sub>z</sub> =	[cos&theta;, -sin&theta;, 0; sin&theta;, cos&theta;, 0; 0, 0 1]</code></p>
    <p>Similarly, we can develop matrices R<sub>x</sub> and R<sub>y</sub> that rotate about the x and y axes by angles &phi; and &psi;, respectively.</p>
    <p><code>R<sub>x</sub> =	[1,	0, 0; 0, cos&phi;, -sin&phi;; 0, sin&phi;, cos&phi;]</code></p>
    <p><code>R<sub>y</sub> =	[cos&psi;, 0, sin&psi;; 0, 1, 0; -sin&psi;, 0, cos&psi;]</code></p>
    <p><code>P* = R<sub>x</sub> * R<sub>y</sub> * R<sub>z</sub> * P</code></p>
    <div class="float-sm-right">
        <video controls class="fig"><source src="Fig_12_7.mp4" type="video/mp4">Figure 12.7</video>
        <p class="figure-name"><b>Figure 12.7: Solid Cubes</b></p>
    </div>
    <p>An example of a script to rotate the solid cube drawn in Chapter 11 is shown in Listing 12.4. The major problem with rotating solid objects is that the coordinates of the object are defined as arrays of points. However, the rotation matrices need each set of coordinates in single rows. To accomplish this, we will use the <code>reshape(...)</code> function to transform the coordinates to and from the row vectors necessary for the coordinate rotation.</p>
    <p>The results after running this script are shown in Figure 12.7. Notice that the mechanization of the top face has caused a "wrapped parcel" effect on the light reflections off that surface.</p>
    <span class="listing">Listing 12.4</span>
</div>

<!-- Solving Simultaneous Linear Equations -->
<h2 id="12_5">12.5 Solving Simultaneous Linear Equations</h2>
<div class="container">
    <p>A common use for matrix division is solving simultaneous linear equations. To be solvable, simultaneous linear equations must be expressed as N independent equations involving N unknown variables, x<sub>i</sub>. They are usually expressed in the following form:</p>
    <p><code>A<sub>11</sub>x<sub>1</sub> + A<sub>12</sub>x<sub>2</sub> + ... + A<sub>1N</sub>x<sub>N</sub> = c<sub>1</sub></code></p>
    <p><code>A<sub>21</sub>x<sub>1</sub> + A<sub>22</sub>x<sub>2</sub> + ... + A<sub>2N</sub>x<sub>N</sub> = c<sub>2</sub></code></p>
    <p> ... </p>
    <p><code>A<sub>N1</sub>x<sub>1</sub> + A<sub>N2</sub>x<sub>2</sub> + ... + A<sub>NN</sub>x<sub>N</sub> = c<sub>N</sub></code></p>
    <p>In matrix form, they can be expressed as follows:</p>
    <p><code>A<sub>N x N</sub> = X<sub>N x 1</sub> = C<sub>N x 1</sub></code></p>
    <p>from which, since all of the values in A and C are constants, we can immediately solve for the column vector X by back division:</p>
    <p><code>X = A\C</code></p>
    <p>or by using the matrix inverse function:</p>
    <p><code>X = inv(A) * C</code></p>
</div>

<!-- Intersecting Lines -->
<h3 id="12_5_1">12.5.1 Intersecting Lines</h3>
<div class="container clearfix">
    <div class="float-sm-right card">
        <img src="Fig_12_8.JPG" alt="Figure 12.8" class="fig card-img">
        <p class="figure-name card-title">Figure 12.8: Lines intersecting</p>
    </div>
    <p>A typical example of a simultaneous equation problem might take the following form. Consider two straight lines on a plot with the following general form:</p>
    <p><code>A<sub>11</sub>x + A<sub>12</sub>y = c<sub>1</sub></code></p>
    <p><code>A<sub>21</sub>x + A<sub>22</sub>y = c<sub>2</sub></code></p>
    <p>These lines intersect at some point P (x, y) that is the solution to both of these equations. The equations can be rewritten in matrix form as follows:</p>
    <p><code>A * V = c</code></p>
    <p>where <code>c</code> is the column vector <code>[c1 c2]'</code> and <code>V</code> is the required result, the column vector <code>[x y]'</code>. The solution is obtained by matrix division as follows:</p>
    <p><code>V = A \ c</code></p>
    <p>Recall that back divide, like the <code>inv(...)</code> function, will fail to produce a result if the matrix is singular, that is, has two rows or columns that have a linear relationship. In the specific example of two intersecting lines, this singularity occurs when the two lines are parallel, in which case there is no point of intersection. Listing 12.5 shows the solution to a pair of simultaneous equations.</p>
    <p>Figure 12.8 shows the result of this script.</p>
    <span class="listing">Listing 12.5</span>
</div>

<!-- Engineering Examples -->
<h2 id="12_6">12.6 Engineering Examples</h2>
<div class="container">
    <p>The following examples illustrate applications of the matrix capabilities discussed in this chapter.</p>
</div>

<!-- Ceramic Composition -->
<h3 id="12_6_1">12.6.1 Ceramic Composition</h3>
<div class="container">
    <p>Industrial ceramics plants require mixtures with precise formulations in order to produce products of consistent quality. For example, a factory might require 100 kg of a mix consisting of 67% silica, 5% alumina, 2% calcium oxide, and 26% magnesium oxide. However, the raw material provided is not pure quantities of these materials. Rather, they are delivered as batches of material that consist of the required components in different proportions. Each batch of raw materials is analyzed to determine their composition, and we will need to do the analysis to determine the proportions of the raw materials to mix in order to accomplish the appropriate formulation. The raw materials we will use here are feldspar, diatomite, magnesite, and talc. Table 12.1 illustrates a typical analysis of the composition of these compounds.</p>
    <table class="table">
        <thead>
            <tr>
                <th></th>
                <th>Silica</th>
                <th>Alumina</th>
                <th>CaO</th>
                <th>MgO</th>
            </tr>
        </thead>
        <tr>
            <td>Feldspar</td>
            <td>0.6950</td>
            <td>0.1750</td>
            <td>0.0080</td>
            <td>0.1220</td>
        </tr>
        <tr>
            <td>Diatomite</td>
            <td>0.8970</td>
            <td>0.0372</td>
            <td>0.0035</td>
            <td>0.0623</td>
        </tr>
        <tr>
            <td>Magnesite</td>
            <td>0.0670</td>
            <td>0.0230</td>
            <td>0.0600</td>
            <td>0.8500</td>
        </tr>
        <tr>
            <td>Talc</td>
            <td>0.6920</td>
            <td>0.0160</td>
            <td>0.0250</td>
            <td>0.2670</td>
        </tr>
    </table>
    <p>For example, if we mixed W<sub>f</sub> kg of feldspar, W<sub>d</sub> kg of diatomite, W<sub>m</sub> kg of magnesite, and W<sub>t</sub> kg of talc, the amount of silica would be 0.695 W<sub>f</sub> + 0.897 W<sub>d</sub> + 0.067 W<sub>m</sub> + 0.692 W<sub>t</sub>. Repeating this equation for the other components produces a matrix equation that reduces to:</p>
    <p><code>C = A * W</code></p>
    <p>where C is the required composition of the resulting mix, A is a 4 x 4 matrix showing the results of analyzing the four raw materials, and W is the proportions in which should we mix the raw material to produce the desired result. We find the appropriate amounts of the raw material by solving these equations:</p>
    <p><code>W = A\B</code></p>
    <p>A script that works this problem is shown in Listing 12.6.</p>
    <span class="listing">Listing 12.6</span>
</div>

<!-- Analyzing an Electrical Circuit -->
<h3 id="12_6_2">12.6.2 Analyzing an Electrical Circuit</h3>
<div class="container clearfix">
    <p>Figure 12.9 illustrates a typical electrical circuit with two voltage sources connected to five resistors with three closed loops. The voltages and resistances are given. We are asked to determine the voltage drop across R1. Solution techniques apply Ohm’s Law to the voltage drops around each closed circuit. When this technique is applied, the equations are as follows:</p>
    <div class="float-sm-right card">
        <img src="Fig_12_9.JPG" alt="Figure 12.9" class="fig card-img">
        <p class="figure-name card-title">Figure 12.9: Typical electrical circuit</p>
    </div>
    <p><code>V<sub>1</sub> = i<sub>1</sub> * R<sub>1</sub> + (i<sub>1</sub> – i<sub>2</sub>) * R<sub>4</sub>
    <br>0 = i<sub>2</sub> * R<sub>2</sub> + (i<sub>2</sub> – i<sub>3</sub>) * R<sub>5</sub> + (i<sub>2</sub> – i<sub>1</sub>) * R<sub>4</sub>
    <br>–V<sub>2</sub> = i<sub>3</sub> * R<sub>3</sub> + (i<sub>3</sub> – i<sub>2</sub>) * R<sub>5</sub></code></p>
    <p>When these three equations are manipulated to isolate the three currents, we have the following matrix equation:</p>
    <p><code>V = A * I</code></p>
    <p>which can be solved as usual by:</p>
    <p><code>I = A \ V</code></p>
    <p>The script to accomplish this is shown in Listing 12.7.</p>
    <span class="listing">Listing 12.7</span>
</div>

<!-- Chapter Summary -->
<h3>Chapter Summary</h3>
<div class="container">
    <p><em>This chapter presented two specialized operations performed with matrices:</em></p>
    <ul>
        <li>Matrix multiplication can be used for 2-D and 3-D coordinate rotations by building the appropriate rotation matrices</li>
        <li>Matrix division can be used for solving simultaneous equations by setting up the equations in the general form <code>B = A * x</code>, where the known matrix <code>A</code> is <code>n x n</code> and the known column vector <code>B</code> is <code>n x 1</code>; the unknown vector <code>x</code> is then found by <code>x = A\B</code> or <code>x = inv(A) * B</code></li>
    </ul>
</div>


<!-- [Special Characters]

[Problems] -->


<table align="center">
<tbody>
<tr>
<td><a href="11_Plotting.htm">previous</a></td>
<td><a href="Contents.htm">home</a></td>
<td><a href="13_Images.htm">next</a></td>
</tr>
</tbody>
</table>

</body>
</html>
